<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>吹雨听风</title>
  
  <subtitle>热爱写代码.</subtitle>
  <link href="https://www.wewx.cn/atom.xml" rel="self"/>
  
  <link href="https://www.wewx.cn/"/>
  <updated>2023-06-01T15:13:37.686Z</updated>
  <id>https://www.wewx.cn/</id>
  
  <author>
    <name>吹雨听风</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>在 AWS CloudWatch Logs Insights 中进行日志数据的过滤、解析</title>
    <link href="https://www.wewx.cn/2023/03/15/logs-insight-in-aws-cloudwatch.html"/>
    <id>https://www.wewx.cn/2023/03/15/logs-insight-in-aws-cloudwatch.html</id>
    <published>2023-03-15T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>CloudWatch Logs Insights 是一项 AWS 服务，用于分析和查询存储在 CloudWatch 日志中的数据。通过使用 CloudWatch Logs Insights，您可以执行强大的查询操作来过滤、解析和分组日志数据，从而获得有关日志事件的有价值的信息。</p><p>下面是在 CloudWatch Logs Insights 中使用的2个关键操作：过滤（Filter）、解析（Parse）。</p><ol><li>过滤（Filter）：通过使用过滤器，您可以根据特定的条件筛选出感兴趣的日志事件。过滤器可以根据文本内容、时间戳、字段值等进行设置。通过过滤操作，您可以限制查询的范围，仅关注满足特定条件的日志事件。</li><li>解析（Parse）：在 CloudWatch Logs Insights 中，解析操作用于从日志事件中提取特定的字段或信息。解析允许您使用模式匹配来识别和提取感兴趣的数据。您可以根据特定的模式定义解析规则，然后将匹配的数据提取到命名的字段中，以便进一步分析和使用。</li></ol><p>这些操作可以结合使用，以构建复杂和有针对性的查询，以满足您的具体需求。</p><p>假设您有一个应用程序将一个经过字符串化的 JSON 记录到 CloudWatch 日志中，并且您有一个要对这些数据进行某种类型的分析的需求。以下是 JSON 示例：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span> <span class="attr">&quot;request_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;abc123&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/servicea/hello&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;process_time&quot;</span><span class="punctuation">:</span> <span class="number">14.433</span> <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>以下是记录这个 JSON 时的日志样式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2020-06-25 INFO response from server: &#123; &quot;request_id&quot;: &quot;abc123&quot;, &quot;path&quot;: &quot;/servicea/hello&quot;, &quot;process_time&quot;: 14.433 &#125;</span><br></pre></td></tr></table></figure><p>假设您想要按 process_time 从大到小排序查询结构以便对请求做优化。让我们看看如何在 CloudWatch Logs Insights 中构建一个查询，以获得这个输出：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">|-------------------|--------------|</span><br><span class="line">|  path             | process_time |</span><br><span class="line">|-------------------|--------------|</span><br><span class="line">|  /servicea/hello  | 287.3332     |</span><br><span class="line">|  /servicea/hello  | 125.98323    |</span><br><span class="line">|-------------------|--------------|</span><br></pre></td></tr></table></figure><p>首先，由于每个 CloudWatch 日志事件本身就是一个 JSON 对象，我们使用以下方式仅提取出日志消息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fields @message</span><br></pre></td></tr></table></figure><p>这样我们就可以得到所有的日志。接下来，让我们过滤掉不需要的日志语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fields @message |</span><br><span class="line">filter @message like &#x27;response from server&#x27;</span><br></pre></td></tr></table></figure><p>这样我们就得到了仅包含记录请求响应的日志。</p><p>接下来，我们需要提取 process_time，以便稍后对其进行排序。使用 <code>parse</code> 命令来提取客户端 ID：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fields @message </span><br><span class="line">| filter @message like &#x27;response from server&#x27;</span><br><span class="line">| parse @message &#x27;&quot;process_time&quot;:*&#125; &#x27;as process_time</span><br><span class="line">| fields @timestamp, @message, abs(process_time) as t</span><br><span class="line">| sort t desc</span><br><span class="line">| limit 200</span><br></pre></td></tr></table></figure><p>上述 <code>parse</code> 语句的作用是将我们记录在日志中的 process_time 字段给提取出来，当它在模式中找到类似 * 的通配符时，它将该值提取到以 “as” 后面命名的字段中。但此时是字符串类型，无法对其直接进行排序才做，还需将其换为换数值类型。</p><p>现在，我们就可以获取按照 process_time 从大到小的排序结果。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;CloudWatch Logs Insights 是一项 AWS 服务，用于分析和查询存储在 CloudWatch 日志中的数据。通过使用 CloudWatch Logs Insights，您可以执行强大的查询操作来过滤、解析和分组日志数据，从而获得有关日志事件的有价值的信</summary>
      
    
    
    
    
    <category term="编程" scheme="https://www.wewx.cn/tags/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="aws" scheme="https://www.wewx.cn/tags/aws/"/>
    
  </entry>
  
  <entry>
    <title>消息队列：RabbitMQ vs Kafka vs Redis vs NSQ vs Pulsar</title>
    <link href="https://www.wewx.cn/2023/02/14/about-message-queue-you-must-know.html"/>
    <id>https://www.wewx.cn/2023/02/14/about-message-queue-you-must-know.html</id>
    <published>2023-02-14T02:36:48.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>在现代软件系统中，消息队列可谓是非常基础的软件，尤其在异步化的微服务架构中。消息队列可确保 用服务之间通信的可靠和稳定，同时使消息在系统全局内部得到监控和治理。</p><p>市面有许多消息队列产品，如成熟的 RabbitMQ，还有后期之秀如 Pulsar 和 NSQ。这些产品的功、特点、支持的数据规模各有不同，本文将对一些主流的消息产品进行基本的对比。</p><h2 id="消息队列使用场景"><a href="#消息队列使用场景" class="headerlink" title="消息队列使用场景"></a>消息队列使用场景</h2><p>消息队列的应用非常广泛，如在分布式系统中承担着消息通信的任务，提供异步化、可靠的消息传递服务; 在物联网系统中承担消息下发与数据汇集的工作， 是物联网平台中不可或缺的组成部份等。</p><h3 id="通信服务"><a href="#通信服务" class="headerlink" title="通信服务"></a>通信服务</h3><p>在微服务系统或分布式系统中，服务与服务之间有两种比较常见的通信方式：同步通信与异步通信。</p><p>在同步通信中，服务的调用方在发请调用后，面要等待服务提供方的响应，常在 http &#x2F; rest 或 rcp 协议上运行。相反的，在异步的通信中，调用方将在消息发出后不必等待服务提供方的响应，此时通常面要使用消息队列产品来进行消息的治理。</p><p>异步通信相比于同步通信有许多的优点。</p><p>首先，异步通信是非阻塞的。调用方和服务方并不会直接的交互，调用方在消息发送成功后通信就完成了，不会等待其他服务对消息的处理结果，因此可以优化数据链路和数据流。</p><p>其次，提供更好的灵活性和扩展性。消息队例的引入，降低了系统组件之间的耦合，组件和组件之间的灵活性将大大提升，同样，由于组件之间不再直接进行通信，扩展性与伸缩性也会更好。</p><p>第三，提高更好的可用性。服务的调用方和服务提供方双方之间不直接联系，而是调用方将请求都发送给消息队列。利用消息队列对原本相互依赖的组件和系统时行分离，可以极大的提升容错的能力，即使在服务提供方故障时，调用方依然可以继续和队列进行交互，从而保证或局部保证了系统的可用性。</p><h3 id="消息服务"><a href="#消息服务" class="headerlink" title="消息服务"></a>消息服务</h3><p>在即时通讯 (IM) 系统中，消息队列了常被用于以下场景：</p><ol><li>异步处理消息：IM 系统的消息处理需要耗时，例如图像转换，语音识别，文本分析等。消息队列可以用来缓存这些任务，使它们在后台独立的线程中处理，避免阻塞用户请求，提高系统效率。</li><li>解耦消息处理组件：IM 系统中的多个组件之间通信通常需要耗时，消息队列可以被用来解耦这些组件，避免相互影响，提高系统的稳定性。</li><li>消息持久化：消息队列可以存储消息，即使在系统宕机或其他异常情况下，消息也不会丢失。这对于 IM 系统中的消息通知等重要信息是非常有价值的。</li></ol><p>消息队列为 IM 系统提供了一个高效的消息管理机制，帮助 IM 系统提高效率，提高稳定性，保证消息的可靠性。</p><h3 id="物联网"><a href="#物联网" class="headerlink" title="物联网"></a>物联网</h3><p>消息列队同样在物联网系统中被用来解决各种问题：</p><ol><li>解耦系统组件：物联网系统通常包括大量的组件，例如传感器，设备，云端服务器等。消息队列可以被用来解耦这些组件，避免相互依赖导致的系统停滞。</li><li>实现异步消息处理：物联网系统中的消息处理通常需要耗时，消息队列可以用来缓存这些任务，使它们在后台独立的线程中处理，避免阻塞其他任务，提高系统效率。</li><li>保证数据一致性：在物联网系统中，数据的传输通常需要处理大量的数据，消息队列可以用来缓存数据，确保数据的一致性，防止数据丢失或出错。</li><li>支持流量削峰：物联网系统中的数据流量可能在短时间内暴增，消息队列可以用来缓存数据，避免系统因数据流量过大而崩溃。</li></ol><p>总的来说，消息队列在现在系统中有着不可或缺的地位，常用于实现异步通讯、应用解藕、削峰平谷等功能。</p><h2 id="消息对列常见协议"><a href="#消息对列常见协议" class="headerlink" title="消息对列常见协议"></a>消息对列常见协议</h2><h3 id="JMS"><a href="#JMS" class="headerlink" title="JMS"></a>JMS</h3><p>Java Message Service的缩写，即Java消息服务。当然，JMS是与语言无关的协议标准，只要遵循该协议2个组件即可时行消息通信。</p><h3 id="STOMP"><a href="#STOMP" class="headerlink" title="STOMP"></a>STOMP</h3><p>即<strong>流文本定向消息协议</strong>（Streaming Text Orientated Messaging Protocal），简单(流)文本定向消息协议，它提供了一个可互操作的连接格式，允许STOMP客户端与任意STOMP消息代理（Broker）进行交互。STOMP协议由于设计简单，易于开发客户端，因此在多种语言和多种平台上得到广泛地应用。</p><p>代表产品为：ActiveMQ、Apollo</p><h3 id="AMQP"><a href="#AMQP" class="headerlink" title="AMQP"></a>AMQP</h3><p>即<strong>高级消息队列协议</strong>（Advanced Message Queuing Protocol）。</p><p>一个提供统一消息服务的应用层标准高级消息队列协议，与 HTTP 一样，AMQP 也是应用层协议的一个开放标准，为面向消息的中间件设计。</p><p>基于此协议的客户端与消息中间件可传递消息，并不受客户端&#x2F;中间件不同产品，不同的开发语言等条件的限制。</p><p>RabbitMQ 是 AMQP 消息队列最有名的开源实现。</p><h3 id="MQTT"><a href="#MQTT" class="headerlink" title="MQTT"></a>MQTT</h3><p>即<strong>消息队列遥测传输</strong>（Message Queuing Telemetry Transport）。由IBM开发，现在被广泛用于物联网场景。因为他的特点就是轻量，简单，开放和易于实现。所以它常用于很多计算能力有限、带宽低、网络不可靠的远程通信应用场景。</p><h2 id="产品简单对比"><a href="#产品简单对比" class="headerlink" title="产品简单对比"></a>产品简单对比</h2><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>我们常把Redis作为内存数据库来用，内存数据存储是它的核心功能，当然也用作高性的消息代理。不过 Redis 与其他消息代理有点不同。</p><p>需要特别注意的是，Redis 没有持久性，而是将其内存转储到磁盘&#x2F;数据库中。它也非常适合实时数据处理。</p><p>自从 Redis 5.0 引入了 pub-sub 功能之后，消息对队得到了提升，也能很好的支付一对多的订阅场景。</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p>RabbitMQ 于 2007 年发布，是最早创建的通用消息代理之一，它是开源的 AMQP 协议的代表。现如今支持 RabbitMQ 还支持 XMPP、SMTP、STOMP 等众多的其他消息协议，同时 RabbitMQ 还支持复杂的路由逻辑，或许这正是它持续火爆的原因。</p><p>在客户端方面，RabbitMQ 支持所有主流编程语言，包括 Python、Java、.NET、PHP、Ruby、JavaScript、Go、Swift 等。</p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>Kafka 由 Linkedin 于 2011 年创建，是一个分布式、分区的、多副本的、多生产者、多订阅者，基于 zookeeper 协调的分布式消息系统。Kafka 优势是支持高吞吐量、低延迟、并且支持持久化存储。同时也拥有众多语言的客户端实现。</p><h3 id="NSQ"><a href="#NSQ" class="headerlink" title="NSQ"></a>NSQ</h3><p>NSQ 是 Go 语言编写的一个开源的实时分布式内存消息队列，其性能十分优异。是近年比较流行的消息队列产品。NSQ提倡分布式和分散的拓扑结构，没有单点故障，支持容错和高可用性，并提供可靠的消息交付保证，同时支持横向扩展，没有任何集中式代理，并且部署也非常的简单。</p><h3 id="Pulsar"><a href="#Pulsar" class="headerlink" title="Pulsar"></a>Pulsar</h3><p>Pulsar是一个高性能，分布式消息系统，它具有高吞吐量，低延迟，高可用性，支持多租户和多语言的特点。Pulsar还提供了一些附加功能，如存储分区，数据持久性，数据备份等。最初由 Yahoo 开发，目前由 Apache 软件基金会管理。</p><h2 id="选择合适的消息队列产品"><a href="#选择合适的消息队列产品" class="headerlink" title="选择合适的消息队列产品"></a>选择合适的消息队列产品</h2><p>前面介绍了几个主流消息对队产品的特性。其中如 Redis &#x2F; RabbitMQ &#x2F; Kafaka 等产品目前处于如日中天的发展阶段，也能被各大云厂商原生支持，但正如前面所描述的，它们在实现方式上却有着天壤之别，这里对于消息队列产品的选择给出一些通用性的建议：</p><h3 id="简单应用、短消息、临时：-Redis"><a href="#简单应用、短消息、临时：-Redis" class="headerlink" title="简单应用、短消息、临时： Redis"></a>简单应用、短消息、临时： Redis</h3><p>Redis 的内存数据库几乎非常适合不需要持久性的短消息用例。因为它提供了极快的服务和内存中功能，Redis 是持久性不是那么重要并且您可以容忍一些丢失的短期保留消息的理想选择。</p><p>Redis 5.0 之后的版本中，增强了 Pub &#x2F; Sub 能力（Stream），如果有简单的一对多场景也可以作为备选。</p><h3 id="汇集海量数据与处理：Kafaka"><a href="#汇集海量数据与处理：Kafaka" class="headerlink" title="汇集海量数据与处理：Kafaka"></a>汇集海量数据与处理：Kafaka</h3><p>Kafka是一个高吞吐量、可靠性、分布式、灵活性和易于扩展的消息系统，专为长时间存储大量数据而构建。主要应用于数据流管理、日志处理、应用间通信和消息队列等场景。</p><h3 id="消息路由复杂：RabbitMQ"><a href="#消息路由复杂：RabbitMQ" class="headerlink" title="消息路由复杂：RabbitMQ"></a>消息路由复杂：RabbitMQ</h3><p>RabbitMQ 作为老牌的、成熟的消息代理，高可用性、易于扩展、强大的路由功能和多种协议支持的特点，周时能够很好的支持复杂路由配置。主要应用于分布式系统的异步通信、应用间消息传递和任务队列等场景。</p><h3 id="需要利用延时特性：-RabbitMQ-x2F-NSQ-x2F-Pulsar-x2F-ActiveMQ"><a href="#需要利用延时特性：-RabbitMQ-x2F-NSQ-x2F-Pulsar-x2F-ActiveMQ" class="headerlink" title="需要利用延时特性： RabbitMQ &#x2F; NSQ &#x2F; Pulsar &#x2F; ActiveMQ"></a>需要利用延时特性： RabbitMQ &#x2F; NSQ &#x2F; Pulsar &#x2F; ActiveMQ</h3><p>延迟队列可让新消息传递操作推迟特定的时常，在等待期间消费者不可见。在实际的使用中常基于此特性实现延迟的重复推送以保证投递的可靠性。如果您的应用有此需求可以考虑这几款支持延时特性的产品。</p><h3 id="需要简化部署：NSQ-x2F-Redis"><a href="#需要简化部署：NSQ-x2F-Redis" class="headerlink" title="需要简化部署：NSQ &#x2F; Redis"></a>需要简化部署：NSQ &#x2F; Redis</h3><p>Redis 作为最基础的产品，已被特大云厂商普遍支持，即使需要私有部署也非常的容易。</p><p>而 NSQ 作为一款近几年兴起的，使用 Go 语言编写的一个开源产品，除了支持良好的性能，还非常的易于配置和部署，并且内置了管理界面。</p><h2 id="消息队列产品技术词汇"><a href="#消息队列产品技术词汇" class="headerlink" title="消息队列产品技术词汇"></a>消息队列产品技术词汇</h2><p>同样，在最后整理了与消息队列上关的技术名词和概念，如有需要可自行进一步深入了解。注意：这里的名词混合了各产品的名词，特定的产品可能只包含下面部份名词也指代的角色。</p><ul><li>Broker：代理，消息队列系统的核心部分，负责维护队列并转发、管理消息，通种表示消息队列服务的实体。</li><li>Message：消息，消息队列中存储的单元数据。</li><li>Producer &#x2F; Publisher：生产者，负责生成并发送消息到消息队列。</li><li>Consumer &#x2F; Subscriber：消费者，负责从消息队列中接收并处理消息。</li><li>Queue：队列，消息存储的容器，消息队列系统可以管理多个队列。</li><li>ACK：确认，消费者在处理完消息后向代理发送确认，代表该消息已经被成功处理。</li><li>Channel：信道，指消息代理中的虚拟连接。它在应用程序和消息代理之间提供了一条用于发送和接收消息的通信路径。</li><li>Topic：主题，消息的类别，生产者向某个主题发送消息，消费者从某个主题接收消息。</li><li>Durable：持久性，消息队列支持持久性消息，即消息不会因系统故障丢失。</li><li>Load Balancing：负载均衡，消息队列系统支持负载均衡，可以将消息均衡地分配给多个消费者。</li><li>Routing：路由，负责将消息队列中的消息分发与路由。根据消息的特征，选择相应的路由规则，将消息分发&#x2F;分配给对应的消费者。</li><li>Pub&#x2F;Sub：发布&#x2F;订阅，消息队列支持发布&#x2F;订阅模型，生产者向主题发布消息，</li><li>Delay Message：延时消息，消息队列中存储的消息在一定的时间后才能被消费者消费。</li><li>Dead Message：死信，超时未消费的消息或是超过最大重试次数后，依然无法消费的消息。</li><li>Dead-Letter-Queue：死信对列，用于处理无法被正常消费的消息队列。</li><li>Exchange：RabbitMQ 的路由代理。将消息路由到一个或多个Queue。Exchange 通常根据 Binding Key、Routing Key 以及 Headers 属性路由消息。</li><li>PlayLoad：负载，等同说消息。</li></ul><p>扩展阅读：</p><ul><li><a href="https://www.confluent.io/kafka-vs-pulsar/">Kafka vs Pulsar - Performance, Features, and Architecture Compared</a></li><li><a href="https://help.aliyun.com/document_detail/177241.html">AMQP和JMS差异</a></li><li><a href="https://www.cnblogs.com/arthinking/p/15422958.html">消息队列那么多，为什么建议深入了解下RabbitMQ？</a></li></ul>]]></content>
    
    
    <summary type="html">在现代软件系统中，消息队列可谓是非常基础的软件，尤其在异步化的微服务架构中。消息队列可确保组件之间通信的可靠和稳定，同时使消息在系统全局内部得到监控和治理。本文对消息队列产品作了些简单的对比，希望对您有用。</summary>
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="消息队列" scheme="https://www.wewx.cn/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
  </entry>
  
  <entry>
    <title>说透 SQL 事务四大特性</title>
    <link href="https://www.wewx.cn/2023/02/01/sql-transaction.html"/>
    <id>https://www.wewx.cn/2023/02/01/sql-transaction.html</id>
    <published>2023-02-01T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>提到数据库事务，相信大家都不陌生，也一定能不加思索的说出 ACID 四大特性：</p><ul><li>原子性 Atomicity<br> 一个事务中的对数据库的所有操作都是一个不可分割的工作单元，这些操作作为一个整体，要么全部执行，要么什么都不做（要么全部成功，要么全部失败）。</li><li>一致性 Consistency<br> 一个事务独立执行的结果，应该保持数据库的一致性，即数据不会因为事务的执行而遭到破坏。</li><li>隔离性 Isolation<br> 在多个事务并发执行时，数据库系统应保证与这些事务先后单独执行时的结果一样，称为事务达到了隔离性的要求。也就是在多个事务并发执行时，保证执行的结果是正确的，就如同单用户执行单个事务一样。</li><li>持久性 Durability<br> 事个事务一旦完成全部操作后，它对数据库的所有更新应永久地反映在数据库中，不会丢失，即使以后系统发生故障也是如此。</li></ul><p>那，除此以外呢？这四大特性是如何保证的、隔离性的是如何分级与实现的等等。如果你也类似的疑问，那么可以往下阅读，本文接下来还将详细探讨事务四大特性背后的原理与细节。</p><h2 id="数据、数据库与数据库管理系统"><a href="#数据、数据库与数据库管理系统" class="headerlink" title="数据、数据库与数据库管理系统"></a>数据、数据库与数据库管理系统</h2><p>在今天，数据库已经是各系统中不可或缺的基础设施。在日常中，我们常说的数据库具有更宽泛的含义，其通常是指数据库管理系统（DBMS, database management system），如 MySQL、PostgreSQL 等。</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/Nfxe93.png" alt="what is mysql?"></p><blockquote><p><a href="https://dev.mysql.com/doc/refman/8.0/en/what-is-mysql.html">MySQL :: MySQL 8.0 Reference Manual :: 1.2.1 What is MySQL?</a></p></blockquote><p>那么 数据库管理系统（DBMS）、 数据库系统（DBS）、数据库（DB）这么些个术语有区别吗？是指的同一个东西吗？当然，其实它们之间是有区别的，定义分别如下：</p><ul><li><p>数据（data）：指的是保存是数据库软件中的信息（有时也称为“记录”）。</p></li><li><p>数据库（Database）：也称为 DB，是长期存储在计算机内、有组织的、统一管理的相关数据的集合。DB且有如下的特点：</p><ul><li>共享性，能在多用户之间进行共享。</li><li>低冗余，数据间具有较低的冗余度。</li><li>相关性，数据和数据之间联系紧密。</li><li>独立性，且有较高的数据独立性。</li></ul></li><li><p>数据库系统（Database System）：也称为 DBS。DBS 是实现有组地、动态地存储大量关联数据的、方便多用户访问的硬件、软件、数据资源共同组成的系统。</p></li><li><p>数据库管理系统（Database Management System）：也称为 DBMS。它是位于用户与操作系统之间的一层数据管理软件，它为用户或应用程序提供访问 DB 的方法，包括 DB 的建立、查询、更新及各种数据据的控制和管理。DBMS 根据管理的数据之间的联系方式不同又分为多种类型：</p><ul><li>层次型，按记录来存取数据。</li><li>网状型，采用网状原理和方法，以网状数据模型为基础建立的数据库。记录类型为结点的网络结构，即一个结点可以有一个或多个下级结点，也可以有一个或多个上级结点，两个结点之间甚至可以有多种联系。代表：DBTG。</li><li>关系型（RDBMS），采用了关系模型来组织数据的数据库，其以行和列的形式存储数据，以便于用户理解。代表：MySQL、 MariaDB、SQL Server 等。</li><li>面向对象型（OODBMS）。如：Versant Object Database 等。</li></ul><p> 目前比较用的是 RDBMS 与 OODBMS。至于它们二者的详细对比，大家阅读这篇文章：<a href="https://www.geeksforgeeks.org/difference-between-rdbms-and-oodbms/"># Difference between RDBMS and OODBMS</a></p></li></ul><p>我们最为常见的 MySQL 它就是 DBMS，其中包含了“数据库”。这里画了两张图，希望能帮助大家更好的理解前面的几个概念。</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/DBMS%E4%B8%8EDB%E7%9A%84%E8%81%94%E7%B3%BB-1.png" alt="DBMS与DB的联系-1"></p><p>图1：可以看到DBMS为于用户和数据库之间，为用户和程序提供访问与管理数据的途径。</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/DBMS%E4%B8%8EDB%E7%9A%84%E8%81%94%E7%B3%BB-db_datum.png" alt="DBMS与DB的联系-db_datum"></p><p>图2：数据库与数据之间的联系。</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/DBMS%E4%B8%8EDB%E7%9A%84%E8%81%94%E7%B3%BB-all.png" alt="DBMS与DB的联系-all"></p><p>图3：各术语之间的层次图。</p><p>到这里，相信大家对于前面的几个概念有了一定的了解。花这么大篇幅介绍这几个概念，那想必和事务有一些联系吧？没错！</p><p>*<strong>请注意：下文出现的 DBMS 如未特别说明均不特指任一具体的数据库管理系统</strong></p><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>从用户的视角来看，一个事务中的对数据库的一组操作应该是一个独立的单元、不能分割的整体。无论发生什么情况，都必须确保要么完整执行，要么完全不执行。</p><p>在 SQL 定义中，一个事务对应的一组操作序列，由 BEGIN TRANSACTION 语句开始，以 COMMIT 或 ROLLBACK 语句结束。</p><p>COMMIT 语句表示事务成功执行并结束，告诉系统此事务对数据的所有修改都要写入磁盘并开始进入到一个新的正确状态。</p><p>ROLLBACK 语句则正好相反，表示事务未成功执行，并应该回退。此时告诉系统，此事务对数据库的所有修改都必须被撤销，让数据库回到事务开始时的初始状态。</p><p>事务是数据库系统（DBS）运行的最小逻辑工作单元。前面已提到事务的四大特性，这四大特性其实是由 DBMS 的四大子系统统来分别保证的，它们是：事务管理子系统、完整性子系统、并发控制子系统、恢复管理子系统。</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/DBMS%E4%B8%8EDB%E7%9A%84%E8%81%94%E7%B3%BB-Page-4.png" alt="DBMS与DB的联系-Page-4"></p><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>原子性可以说是数据库系统本身最基本的职责，它具体是由事务管理子系统结果恢复管理子系统来实现。</p><p>在 MySQL 的实现中，InnoDB 引擎对事务过程中的数据变更总是维持了 UNDO LOG，若要回滚事务，能够通过 REDO 追溯最老版本的方式，将数据全部回滚回来。若用户需要提交事务，则将 REDO LOG 的缓冲区刷新到磁盘。</p><p>REDO 与 UNDO 日志，除了用来保证原子性的实现，还用于保证持久性。</p><h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><p>DBMS 的“完整性子系统” 执行测试任务以保证数据库中数据是正确的，该检查也被称为“完整性检查”。所谓的完整性，是指数据库中数据的正确性、有效性、相容性，防止错误的数据进入。</p><p>完整性子系统主要有2大功能：</p><ul><li>监督事务的执行，并测试其是否违反完整性规则</li><li>或有违反，则采取操作</li></ul><p>而 完整性规则 由 DBA 或程序开发人员配置。主要有域约束、表约束、断言三大类。</p><p>在 MySQL InnoDB 引擎中，可以通过在创建数据表时定义 Primary Key 和 Unique Key 来定义基本表约束。此外还可以通过编写触发器（断言）的方式来进一步完善约束。通常可选的定义约束的途径有：</p><ul><li>选择合适的字段类型（类型约束）</li><li>定义 Primary Key</li><li>定义 Foreign Key</li><li>定就 Unique Key</li><li>编写触发器</li><li>定义 Default</li><li>定义 Not Null</li></ul><p>上面说的 Primary Key、Foreign Key、Unique Key 不是在创建索引么。没错，确实是索引。但是在创建上述索引的时候会同时创建对应的约束，索引是一个数据结束，而约束是用来保证数据的完整性。</p><p>可以通过 <code>select constraint_name, constraint_type from table_name</code> 语句来查看数据表约束。</p><p>对于 MySQL 约束的文档可以查看： <a href="https://dev.mysql.com/doc/refman/8.0/en/create-table-check-constraints.html">MySQL :: MySQL 8.0 Reference Manual :: 13.1.20.6 CHECK Constraints</a></p><h2 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h2><p>所谓“隔离”，就是让同时执行的多个事务保持各自的独立性，避免相互影响。</p><p>同时执行（并发）多个事务会带来三个问题：更新丢失、读到脏数据、不可重复读。如果系统不加以控制，那么数据库的完整性可能会遭到破坏。DBMS 的并发控制子系统正是用来调度多事务的执行并保证隔离性。</p><h3 id="更新丢失"><a href="#更新丢失" class="headerlink" title="更新丢失"></a>更新丢失</h3><p>先看一个并发事务模拟：</p><table><thead><tr><th>时间</th><th>事务T1</th><th>数据库中 A 的值</th><th>事务T2</th></tr></thead><tbody><tr><td>t0</td><td></td><td>100</td><td></td></tr><tr><td>t1</td><td>Read A</td><td></td><td></td></tr><tr><td>t2</td><td></td><td></td><td>Read A</td></tr><tr><td>t3</td><td>A &#x3D; A - 30</td><td></td><td></td></tr><tr><td>t4</td><td></td><td></td><td>A &#x3D; A * 2</td></tr><tr><td>t5</td><td>Update A</td><td></td><td></td></tr><tr><td>t6</td><td></td><td>70</td><td></td></tr><tr><td>t7</td><td></td><td></td><td>Update A</td></tr><tr><td>t8</td><td></td><td>200</td><td></td></tr></tbody></table><p>在上面的事务中，如果按次序执行，最后 A 的值是 200。这肯定不是正确的， T1 对 A 的更新操作丢失了。</p><h3 id="读到脏数据"><a href="#读到脏数据" class="headerlink" title="读到脏数据"></a>读到脏数据</h3><p>什么样的数据是脏数据呢？指的是事务中未提交的随后被撤销的数据。我们再看一个并发事务模拟：</p><table><thead><tr><th>时间</th><th>事务T1</th><th>数据库中 A 的值</th><th>事务T2</th></tr></thead><tbody><tr><td>t0</td><td></td><td>100</td><td></td></tr><tr><td>t1</td><td>Read A</td><td></td><td></td></tr><tr><td>t2</td><td>A &#x3D; A - 30</td><td></td><td></td></tr><tr><td>t3</td><td>Update A</td><td></td><td></td></tr><tr><td>t4</td><td></td><td>70</td><td>Read A</td></tr><tr><td>t5</td><td>ROLLBACK</td><td></td><td></td></tr><tr><td>t6</td><td></td><td>100</td><td></td></tr></tbody></table><p>在上面的事务中，在 t4 时该，T1 事务把 A 的值修改为了 70，但尚未提交（COMMIT），此时并行的 T2 事务读取到了 A 的值（70），但 T1 事务随后执行了 ROLLBACK 操作，而 T2 事务还在使用 70 这个值。这也显然是不正确的（脏数据）。</p><h3 id="不可重复读"><a href="#不可重复读" class="headerlink" title="不可重复读"></a>不可重复读</h3><p>不可重复读指的是，在一个事务中，对同一个数据项的 2次（或多次）读操作，读取到的值不一致的现象。还是先看一个并发事务模拟：</p><table><thead><tr><th>时间</th><th>事务T1</th><th>数据库中 A 的值</th><th>事务T2</th></tr></thead><tbody><tr><td>t0</td><td></td><td>100</td><td></td></tr><tr><td>t1</td><td>Read A</td><td></td><td></td></tr><tr><td>t2</td><td></td><td></td><td>Read A</td></tr><tr><td>t3</td><td></td><td></td><td>A &#x3D; A * 2</td></tr><tr><td>t4</td><td></td><td></td><td>UPDATE A</td></tr><tr><td>t5</td><td></td><td>200</td><td>COMMIT</td></tr><tr><td>t6</td><td>Read A</td><td></td><td></td></tr></tbody></table><p>在上面的表中，T1 事务中两次读 A 数据，读到的值却是不一样的，这也显然是不正确的。</p><p>那么并发控制子系统到底是如何来解决上述的几个问题的呢？– 锁技术。</p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>锁是一个与数据有关的变量，对应用于该数据的操作页言，锁描述的是该数据的状态。</p><p>在数据库中，锁主要有两种：排他锁与共享锁。</p><h4 id="排他锁"><a href="#排他锁" class="headerlink" title="排他锁"></a>排他锁</h4><p>排他锁也称为独占锁、写锁，是数据库中最为常用的一种锁，也叫 X 锁。</p><p>如果一个事务对一个数据项成功的实现了 X 锁，那么在该 X锁释放之前，数据库不允许其他事务对数据项加任务类型的锁。</p><p>X锁的操作有两个：</p><ol><li>申请 X 锁。若事务对数据项申请加X锁成功，则可以读、写该数据项。若失败，事务会进行等待队列，直到成功申请到X锁事务才能继续。</li><li>释放 X 锁。数据库系统中并没有提供解除X锁的操作，而是在 ROLLBACK、COMMIT 操作时，自动的释放 X 锁。原因是，如果过早的解除了X锁，那么其他事务依然会读取到未提交的数据。</li></ol><h4 id="共享锁"><a href="#共享锁" class="headerlink" title="共享锁"></a>共享锁</h4><p>由于 X 锁的并发度太低，一次只能有一个事务获取 X 锁，其他事务即使只需要读数据，也只能在队列等候。为了解决这个问题，就引入了共享锁。也就 S 锁。</p><p>事务对数据项成功加上 S 锁后，系统依然允许其他事务对该数据项加S锁，但是该数据项所有的S锁接触之前，不允许任何事务对该数据项加上 X 锁。</p><p>两种锁的兼容性：</p><p>|     | X 锁   | S 锁  |<br>|: — :|: — :|: — :|<br>| X 锁  |   不兼容  | 不兼容    |<br>| S 锁   |   不兼容  |  <strong>兼容</strong>   |</p><p>如果并行事务向同一数据项申请了不相容的锁，那么后提出的事务必须在队列中等待。</p><p>使用 S 锁有三个操作：</p><ol><li>申请 S 锁操作。事务如果对数据项成功加上 S 锁，则可以读取数据，但不能写数据。如是加上 S 锁不成功，那么这个事务将进入对队排队，一直到成功加上 S 锁为止。</li><li>升级和写操作。事务如果要对数据项进行写操作，那么需要先将 S 锁升级为 X 锁。如果升级成功可以直接写数据，若失败，事务将入进入队列待待。</li><li>释放 S 锁操作。事务解除对数据项的 S 锁。</li></ol><p>从上面的操作步骤不难看到，S 锁只能读，不能写。若需要写，则必须先升级为 X 锁。同时由于 S 锁只能读，因此事务可以随时释放 S 锁。</p><p>上面 2 种锁，加锁的对象可以很大，也可以很小。拿 MySQL 来说，锁可以加在表上，数据记录行上，也可以加在某一个属性上。锁对象的大小称之为锁的粒度。</p><p>加锁虽然能解决事务并行的问题，但也会带来新的问题。如加锁会增加系统的开销，给数据库系统带来带来性能压力，因此在实际使用中，需要结合具体的业务来决定加锁的粒度。如果一个事务需要更新大量的数据，可以考虑把锁加在表上，反之则应该主加锁的粒度尽可能的小。</p><h4 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h4><p>在 MySQL 的 InnoDB 引擎中，还支持另外一种锁，称之为“意向锁”。意向锁是将锁定的对象分为多个层次，借助意向锁，InnoDB 支持可以支持多粒度锁定，这种锁定允许事务在行级锁和表级锁上同时加锁。</p><p>意向锁也分为两种：</p><ul><li>意向共享锁：事务想要获得一张表中某几行的共享锁，也称为 IS 锁。</li><li>意向排他锁：事务想要获得一张表中某几行的排他锁，也称为 IX 锁。</li></ul><p>于是，在 MySQL 的 InnoDB 引擎中锁的兼容矩阵变成了下面这样：</p><p>|         | X 锁    | S 锁     | IX 锁   | IS 锁   |<br>| : — : | : — : | : — :  | : — : | : — : |<br>| X 锁    | 不兼容  | 不兼容   |   不兼容      |  不兼容       |<br>| S 锁    | 不兼容  | <strong>兼容</strong> |      不兼容   |   <strong>兼容</strong>      |<br>| IX 锁   |    不兼容     |    <strong>兼容</strong>      |      <strong>兼容</strong>    |     <strong>兼容</strong>     |<br>| IS 锁         | 不兼容       |     <strong>兼容</strong>     |    <strong>兼容</strong>      |  <strong>兼容</strong>       |</p><p>通过各种锁，是否能够顺利的解决前面提到的三个问题呢？再来看一个并行的事务模拟：</p><table><thead><tr><th>时间</th><th>事务T1</th><th>数据库中 A 的值</th><th>事务T2</th></tr></thead><tbody><tr><td>t0</td><td></td><td>100</td><td></td></tr><tr><td>t1</td><td>XRead A (加 X 锁)</td><td></td><td></td></tr><tr><td>t2</td><td></td><td></td><td>XRead A （加锁失败）</td></tr><tr><td>t3</td><td>A &#x3D; A - 30</td><td></td><td>wait</td></tr><tr><td>t4</td><td>UPDATE A</td><td></td><td>wait</td></tr><tr><td>t5</td><td></td><td>70</td><td>wait</td></tr><tr><td>t6</td><td>COMMIT (释放 X 锁)</td><td></td><td>wait</td></tr><tr><td>t7</td><td></td><td></td><td>XRead A   （加 X 锁成功）</td></tr><tr><td>t8</td><td></td><td>70</td><td></td></tr><tr><td>t9</td><td></td><td></td><td>A &#x3D; A * 2</td></tr><tr><td>t10</td><td></td><td></td><td>UPDATE A</td></tr><tr><td>t11</td><td></td><td>140</td><td>COMMIT</td></tr><tr><td>t12</td><td></td><td></td><td></td></tr></tbody></table><p>在 t1 时该，事务T1 成功的对数据 A 加上了 X 锁，所以在 t2 时该，各务T2对A加上 X 锁时就会失败。在事务 T1 执行操作的过程中，事务 T2 将一直处理等待状态，直接事务 T1 COMMIT 并释放 X 锁才会继续执行，因此，通过锁技术，可以把多个并行的操作改为串行方式执行，能够有效的避免读到脏数据、更新丢失以及不可能重复读的问题。但锁的引入也还了新的问题，那便是<strong>死锁</strong>。</p><p>再再再来看一个模拟：</p><table><thead><tr><th>时间</th><th>事务T1</th><th>数据库中 A 的值</th><th>事务T2</th></tr></thead><tbody><tr><td>t0</td><td></td><td>100</td><td></td></tr><tr><td>t1</td><td>SRead A (加 S 锁)</td><td></td><td></td></tr><tr><td>t2</td><td></td><td></td><td>SRead A （加 S 锁）</td></tr><tr><td>t3</td><td>A &#x3D; A - 30</td><td></td><td></td></tr><tr><td>t4</td><td></td><td></td><td>A &#x3D; A * 2</td></tr><tr><td>t5</td><td>UPDATE A (会失败)</td><td></td><td></td></tr><tr><td>t6</td><td></td><td></td><td>UPDATE A  (会失败)</td></tr><tr><td>t7</td><td>wait</td><td></td><td>wait</td></tr><tr><td>t8</td><td>wait</td><td></td><td>wait</td></tr><tr><td>t9</td><td>…</td><td></td><td>…</td></tr></tbody></table><p>在这个模拟中，t1、t2 时该，事务T1 和事务 T2 都成功的对数据 A 加上了 S 锁，但是事务执行的过程中，他们都需要将 S 锁升级为 X 锁以便更新数据。但根据 X、S 锁的兼容性，在有 S 锁时是无法加上 X 锁的，因此这两个事务都会无限的等待下去，这便是死锁。</p><p>出现死锁时，若系统不进行干预，所有的事务都将无法进行下去。要解决死锁方法也很简单，那就是不等待。</p><h4 id="MySQL-InnoDB-如何解决死锁"><a href="#MySQL-InnoDB-如何解决死锁" class="headerlink" title="MySQL InnoDB 如何解决死锁"></a>MySQL InnoDB 如何解决死锁</h4><p>InnoDB 死锁的 Demo，请看这里 <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlock-example.html">MySQL :: MySQL 8.0 Reference Manual :: 15.7.5.1 An InnoDB Deadlock Example</a></p><p>要解决死锁，最简单的办法就是超时，即所有的等待都不能某个阈值，超过则进行回滚操作，其他的事务也就能继续执行。在 InnoDB 引擎中，可以通过 <code>innodb_lock_wait_timeout</code> 来配置锁的超时时间。</p><p>超时虽然简单，但如果只依赖超时回滚来解决死锁的问题，也存在一些缺陷。例如要回滚的事务是一个非常大的事务，或者是权重比较高的事务，此时回滚则会占用较多的 undo log，且会引影数据库整体的性能。</p><p>因此在 InnoDB 中，除了使用被动的超时机制外，还采了一种叫 等待图（wait-for graph ）的技术来主动的检测死锁。关于死锁检的更多测细节，大家可进一步查看 MySQL 官方文档中的说明 <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-deadlock-detection.html">MySQL :: MySQL 8.0 Reference Manual :: 15.7.5.2 Deadlock Detection</a></p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><p>说动隔离性，不得不提隔离级别。隔离级别用于约束事务的调度，因此先来看看什么是事务的调度。</p><h4 id="事并的调度"><a href="#事并的调度" class="headerlink" title="事并的调度"></a>事并的调度</h4><p>“调度”指的是多个事务操作的执行次序。如果多个事务依次执行，则称为事务的串行调度。如果种用分时的方法，同时处理多个事务，旵称为事务的并发调度。</p><p>串行调度下，事务和事务之间不存在时间上的重叠。但在并行调度时，势必会有部份事务的调度是不正确的，那并发控制子系统又是如何来判断一个并发的调度是正确的呢？</p><h4 id="可串行"><a href="#可串行" class="headerlink" title="可串行"></a>可串行</h4><p>对于多个事务，每个事务中语句的先后顺序在串行调度或并行调度中始终保持一致。并且在并发度调和串行调度的执行的结果一致，那么这个并发调度可称为“可串行化调度”，反之就不是。</p><p>只有可串行化的调度，才能真正在并发调度下获得正确的结果。</p><h4 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h4><p>SQL 标准提供了 4 种隔离级别。分别是：</p><ul><li>READ UNCOMMITTED：读未提交。这是最低的级别，允许事务读到其他事务已提交或未提交的数据（可能读到脏数据）。</li><li>READ COMMITTED：读已提交。允许事务读已提交的数据，但不要求两次读取的值须保持一致，即，不可重复读。</li><li>REPEATABLE READ：可重复读。只允许事务读已提交的数据，并且在两次读同一数据时不允许其他事务修改此数据。</li><li>SERIALIZABLE：可串行化。允许事务与其他事务并发执行，但系统必须保证并发调度是可串行化的。此级别下性能最低。</li></ul><p>上面不同级别的隔离性依次提高。隔离级别越高意味着事务请求锁就越多，或保持锁的时间就会越长。</p><p>隔离级别由标准化组织制定，但实际上各数据库厂商在实现时各有不同，这里同样以 MySQL InnoDB 引擎为例，看看 MySQL 事务隔离性的实现。</p><h4 id="MySQL-InnoDB-的事务隔离性"><a href="#MySQL-InnoDB-的事务隔离性" class="headerlink" title="MySQL InnoDB 的事务隔离性"></a>MySQL InnoDB 的事务隔离性</h4><p>InnoDB 的默认隔离级别是 REPEATABLE READ，但我们可能听说过，InnoDB 在此隔离级别下能达到 SERIALIZABLE 的隔离性。</p><p>InnoDB 会使用 “Next-Key lock” 来进行搜索和索引扫描，避免了幻读的产生，通过基于行锁的 MVCC 版本控制原理来达到重复读和已提交读，最后使配合表锁来实现串行化。 关于相关技术的细节可通过相关文章进行深入的了解，如：</p><ul><li>关于幻读，可阅读 <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-next-key-locking.html">MySQL :: MySQL 8.0 Reference Manual :: 15.7.4 Phantom Rows</a></li><li>关于 Next-Key lock，可阅读 <a href="https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-next-key-locks">MySQL :: MySQL 8.0 Reference Manual :: 15.7.1 InnoDB Locking</a></li><li><a href="https://segmentfault.com/a/1190000040129107">MySQL next-key lock 加锁范围是什么？ - 小航的技术笔记 - SegmentFault 思否</a></li></ul><h2 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h2><p>DBMS 的恢复管理子系统会采取一系列措施保证在任何情况下何持事务的原子性和执久性，确保数据不丢失、不破坏。主要策略就是备份与恢复。</p><p>要在将来进行数据的恢复，那么在平时需要做好备份，否则也没有数据可用于恢复。而要做好备份，其是就是需要做好转储和日志。备份的方式有多种，暂时先不谈了，此处就只说说和事务关系密切的日志：REDO 日志和 UNDO 日志。</p><p>REDO 日志和 UNDO 日志其实是使用一种称作检查点的方法来实现的。DBMS 定时设置检查点，在检查检点时该，将事务修改的数据写入磁盘，并在日志文件中写入一条检查点记录。当 DB 需要时行恢复操作时，则只恢复那此在检查点之后的事务就行了，可以极大的减少 DB 恢复的时间。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们盘点了 SQL 中的事务的四大特及实现的基本原理。其中的隔离性特性，又涉及到事务的4层隔离级别，相关细节技术点本文未作详细的展开，大家可再行深入。</p><h3 id="技术点"><a href="#技术点" class="headerlink" title="技术点"></a>技术点</h3><p>事务关联的技术点比较多，这里做了个简单的罗列，有兴趣也可深入的去了解</p><ul><li>MVCC：Multi-Version Concurrency Control</li><li>Next-Key lock</li><li>脏读、重复读、幻读</li><li>undo log、redo log</li><li>串行化</li><li>锁、共享锁、排他锁、死锁、死锁避免、死锁检测</li><li>约束 与 锁引</li></ul>]]></content>
    
    
    <summary type="html">提到数据库事务，相信大家对 ACID 四大特性不陌生，但这些特性又是如何实现的呢？本文将抛砖引玉，带大家一探究竟。</summary>
    
    
    
    
    <category term="MySQL" scheme="https://www.wewx.cn/tags/MySQL/"/>
    
    <category term="数据库" scheme="https://www.wewx.cn/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>聚合支付系统设计之：退款处理</title>
    <link href="https://www.wewx.cn/2023/01/06/payment-system-desigin-of-refund.html"/>
    <id>https://www.wewx.cn/2023/01/06/payment-system-desigin-of-refund.html</id>
    <published>2023-01-06T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>顾客在商家的系统中完成付款操作后，还可以在一定时间内申请退款。因此聚合支付系统需要面向商家端提供退款能力以便商户系统完成相应操作。</p><h2 id="退款状态机"><a href="#退款状态机" class="headerlink" title="退款状态机"></a>退款状态机</h2><p>以下为退款单的状态转换图：</p><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/%E5%8F%96%E5%90%88%E6%94%AF%E4%BB%98%E9%80%80%E6%AC%BE%E7%8A%B6%E6%80%81%E5%9B%BE.png" alt="取合支付退款状态图"></p><p>Processing： 商户系统向聚合支付系统申请退款成功</p><p>Failed: 聚合支付系统向收单机构申请退款，收单机构返回失败，常见的原因：商家账户或用户账户异常等</p><p>Closed: 因订单超过退款期限，或商家商户余额不足等明确的业务原因失败，此种原因的失败可发起重试</p><p>Success: 退款成功</p><h2 id="退款处理流程"><a href="#退款处理流程" class="headerlink" title="退款处理流程"></a>退款处理流程</h2><p><img src="https://oss-digitcert.oss-cn-shenzhen.aliyuncs.com/uPic/%E5%8F%96%E5%90%88%E6%94%AF%E4%BB%98%E9%80%80%E6%AC%BE%E6%97%B6%E5%BA%8F%E5%9B%BE.png?3" alt="取合支付退款时序图"></p><h3 id="申请退款"><a href="#申请退款" class="headerlink" title="申请退款"></a>申请退款</h3><p>聚合支付系统仅处理支付业务，因此退款需要顾客在商户系统中提出申请，或由商户系统具备权限的运营人员发起，并在商户系统创建退款单。然后向聚合支付系统提出申请，聚合支付系统创建退款单后返回单号给商户系统。</p><p>对于聚合支付系统而言，退款是一个纯异步的操作。退款单创建成功后进入系统处理队列，由处理程序向收单机构发起退款。</p><h3 id="查询退款"><a href="#查询退款" class="headerlink" title="查询退款"></a>查询退款</h3><p>聚合支付系统提供了一组退款接口，其中包括：申请退款接口以及查询退款接口。</p><p>申请退款接口所返回的结果仅代表该次退款请求是否受理成功（含聚合支付系统的退款单号）。由于本身退款的结果部分依赖于用户支付卡银行的处理，所以最终退款结果是否成功还需要通过查询退款接口来确认。或接收来自聚合支付系统的退款结果通知（退款单有状态变化时，聚合支付系统将向商家系统发送退款通知）。</p><h3 id="退款时效"><a href="#退款时效" class="headerlink" title="退款时效"></a>退款时效</h3><p>退款的操作具有相当的复杂性、操作都是异步化的特点，同时不同的收单机构对退款的处理时间也不尽相同：</p><pre><code>- 支付宝、微信支付余额类的支付通常都能在 30 分钟内处理完毕- 使用绑定银行卡支付，退款处理需要 0-5 个工作日- 如果需要重试，则会消耗更多时间</code></pre><p>鉴于退款时间的不确定性，当顾客在商户系统中申请退款成功能时，建议系统向顾客告知退款受理状态，对于款项的到帐时间应预留一定的处理时间，比如向顾客提示退款将会3～7个工作日内按支付方式原路返回并提醒顾客关注付款渠道的通知是比较妥当的作法。</p><h3 id="退款重试"><a href="#退款重试" class="headerlink" title="退款重试"></a>退款重试</h3><p>在上面的状态图中所描述的关闭状态（Closed），商户系统可以进行重试退款。但切记，重试时请<strong>使用上次相同的退款单号</strong>。</p><h3 id="多次退款"><a href="#多次退款" class="headerlink" title="多次退款"></a>多次退款</h3><p>这是因为收单机构都允许对一个交易进行部分退款或多次退款，只要退款总额不超过付款金额就行。在聚合支付系统及收单机构系统中，都将不同的退款单号认定为不同的退款，即使两笔退款发生在同一笔交易下。</p><p>这也就解释了在进行重试退款时为什么不能变更退款单号。</p><p>在部分退款的场景，多次以不同单号重试就可能会造重复退款的情况。即使上次退款没成功能，变更了退款单号并虽不会导致重复退款，但这在语义上也有混淆：到底是申请了2次退款，还是只申请了1次因失败又重试了1次？无法解释。</p><h3 id="正确做法"><a href="#正确做法" class="headerlink" title="正确做法"></a>正确做法</h3><p>重试时不改变退款单号，但增加退款序号，用于标记处理此笔退款的多次处理。</p><h3 id="余额不足"><a href="#余额不足" class="headerlink" title="余额不足"></a>余额不足</h3><p>收单机构给聚合支付系统返回余额不足错误时，聚合支付系统将会给商户系统返回 ** Close 状态**，且原因被标记为 “NOT_ENOUGH”，此时商户系统可在稍后重试。</p><h3 id="什么情况下会出现-“NOT-ENOUGH”"><a href="#什么情况下会出现-“NOT-ENOUGH”" class="headerlink" title="什么情况下会出现 “NOT ENOUGH”"></a>什么情况下会出现 “NOT ENOUGH”</h3><p>当商户在收单机构的账户资金池余额不足时。</p><p>拿微信支付来说，商户与微信支付签约后会有一个资金结算周期，实体行业为 T+1、互联网行业为 T+7 等。如果为 T+1 结算，在每日的凌晨，微信支付会将商户收到的资金结算到商户的结算账户中。</p><p>微信支付的资结算是自动的，无需人工手动申请提现。那么一个订单在付款3天后来申请退款，恰好最近3天商户系统没有交易产生，此时商户在微信支付的待结算的资金池余额为0，申请退款就会无款可退，导致失败。</p><h2 id="完整退款逻辑与解决方案"><a href="#完整退款逻辑与解决方案" class="headerlink" title="完整退款逻辑与解决方案"></a>完整退款逻辑与解决方案</h2><ol><li>退款要支持重试，并且重试时不能改变退款单号;</li><li>一笔交易支持多次退款，商户系统、聚合支付系统做好校验与检查;</li><li>退款的重试动作，应该留在聚合支付系统;</li><li>退款是异步操作，结果应以异步通知为主;</li><li>前端对顾客友好提示，告知顾客关注支付渠道的退款通知;</li><li>商户应采取一定的措施保证其在收单机构的账户中有足够的待结算资金，以便覆盖可能的退款情况。</li></ol>]]></content>
    
    
    <summary type="html">退款是一个相当重要功能，但由于从支付到申请退款的时间跨度长、流程中不确性多、过程异步化程度高，应此在设计退款功能时应妥善考虑各种意外情况以保证退款顺利完成。</summary>
    
    
    
    
    <category term="系统架构设计" scheme="https://www.wewx.cn/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="支付系统" scheme="https://www.wewx.cn/tags/%E6%94%AF%E4%BB%98%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>如何确保一个协程在超时后顺利退出</title>
    <link href="https://www.wewx.cn/2022/11/22/goroutine-timeout.html"/>
    <id>https://www.wewx.cn/2022/11/22/goroutine-timeout.html</id>
    <published>2022-11-22T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>Go 中的协程由于其非常易于使用的特性，在实际的使用中被广泛的应用于各个场中心。在有些场的使用可能并不是很恰当，甚至在特定的场景下定带来其他的问题。</p><h2 id="一个场景"><a href="#一个场景" class="headerlink" title="一个场景"></a>一个场景</h2><p>在 Go 中，通过 crontab 来调度一个任务 AsyncTask() 来处理一些异步工作，调度器每分钟调度 1 次。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如果 AsyncTask 的执行时间，超过了调度间隔，而恰好，AsyncTask 的处理又比较占用系统资源，那么就会有大问题。</p><p>资源的占用会进一步延长 AsyncTask 的处理是间，如此更形成了恶性循环，直至耗尽全部资源。</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8doqt4xpuj30lp0avaac.jpg"></p><h2 id="超时结束"><a href="#超时结束" class="headerlink" title="超时结束"></a>超时结束</h2><p>提到超时，我们首先一定会想到 <code>context.WithTimeout</code>，它提供了简单的方法，可以轻而易举的实现超时功能，于下，我们可以写下如下的代码。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AsyncTask</span><span class="params">()</span></span> &#123;  </span><br><span class="line">   ctx, cancel := context.WithTimeout(context.Background(), time.Second*<span class="number">3</span>)  </span><br><span class="line">   <span class="keyword">defer</span> cancel()  </span><br><span class="line">  </span><br><span class="line">   <span class="keyword">select</span> &#123;  </span><br><span class="line">   <span class="keyword">case</span> &lt;-ctx.Done():  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTask has done&quot;</span>)  </span><br><span class="line">   <span class="keyword">default</span>:  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTask is running&quot;</span>)  </span><br><span class="line">      time.Sleep(time.Second * <span class="number">3</span>)  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>确实，这是一个超时的任务处理器，且考虑了两个方面：</p><ul><li>当 AsyncTask 任务提前处理完成时，退出</li><li>当 AsyncTask 处理完，但时间超过了 1 分钟时，退出</li></ul><p>看似能很完美的运行， AsyncTask 运行时间小于 1 分钟，没有问题。</p><p>但是回到我们上面的问是，当 AsyncTask 运行时间远远超过 1 分钟时，我们前面提到的问是还是存在的，前面的任务运行没有结束，后面的任务又到来了。</p><h2 id="超时后协程会退出吗"><a href="#超时后协程会退出吗" class="headerlink" title="超时后协程会退出吗"></a>超时后协程会退出吗</h2><p>我们可以运行一个 test，在结束时打印一下当前进程空间中的所有协程数量以判断协程是否正确退出：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestTimeoutContextWrapper</span><span class="params">(t *testing.T)</span></span> &#123;  </span><br><span class="line">   t.Helper()  </span><br><span class="line">   <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++ &#123;  </span><br><span class="line">      <span class="keyword">go</span> AsyncTask()  </span><br><span class="line">   &#125;  </span><br><span class="line">   time.Sleep(time.Second * <span class="number">4</span>)  </span><br><span class="line">   t.Log(runtime.NumGoroutine())  </span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>将 AsyncTask 使用协程方式，异步的运行 1000 次，AsyncTask 内部会睡眠 3s 以模拟实际的业务处理耗时。主程序睡眠 4s，最后再打印所有的协程数量。</p><p>运行，并等待 4 秒之后，得到如下的输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    timeout_context_test.go:32: goroutines:  2</span><br><span class="line">--- PASS: TestTimeoutContextWrapper (4.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure><p>证明在超时 3s 后，所以创建的协程都已正确退出。</p><p>那，如果 AsyncTask() 运行时间超过 3s 呢？假设以阻塞 IO 方式运行了 10s，我再次来模拟一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    timeout_context_test.go:32: goroutines:  1002</span><br><span class="line">--- PASS: TestTimeoutContextWrapper (4.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure><p>测试结果证明了我们一开始的问题：在同步阻塞 IO 情况下，select 循环也需要至少等待一次主业务逻辑执行完成（10s），在下次循环时才会检测到超时，然后协程退出。</p><h2 id="如何在超时后直接退出"><a href="#如何在超时后直接退出" class="headerlink" title="如何在超时后直接退出"></a>如何在超时后直接退出</h2><p>我们试试异步非阻塞 IO。将上面的测试代码稍微改一改，把同步 IO 替换成异步 IO：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AsyncTask2</span><span class="params">(c <span class="keyword">chan</span> <span class="type">bool</span>)</span></span> &#123;  </span><br><span class="line">   ctx, cancel := context.WithTimeout(context.Background(), time.Second*<span class="number">10</span>)  </span><br><span class="line">   <span class="keyword">defer</span> cancel()  </span><br><span class="line">   <span class="keyword">select</span> &#123;  </span><br><span class="line">   <span class="keyword">case</span> &lt;-ctx.Done():  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTask2 has done&quot;</span>)  </span><br><span class="line">      c &lt;- <span class="literal">true</span>  </span><br><span class="line">   <span class="keyword">default</span>:  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTask2 is running&quot;</span>)  </span><br><span class="line">   &#125;&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AsyncTaskRunner</span><span class="params">()</span></span> &#123;  </span><br><span class="line">   <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTaskRunner has done&quot;</span>)  </span><br><span class="line">   &#125;()  </span><br><span class="line">   done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>, <span class="number">1</span>)  </span><br><span class="line">   <span class="keyword">go</span> AsyncTask2(done)  </span><br><span class="line">  </span><br><span class="line">   <span class="keyword">select</span> &#123;  </span><br><span class="line">   <span class="keyword">case</span> &lt;-done:  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTask2 done&quot;</span>)  </span><br><span class="line">   <span class="keyword">case</span> &lt;-time.After(time.Second * <span class="number">2</span>):  </span><br><span class="line">      fmt.Println(<span class="string">&quot;AsyncTaskRunner timeout&quot;</span>)  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TestAsyncTaskRunner</span><span class="params">(t *testing.T)</span></span> &#123;  </span><br><span class="line">   t.Helper()  </span><br><span class="line">   <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;  </span><br><span class="line">      <span class="keyword">go</span> AsyncTaskRunner()  </span><br><span class="line">   &#125;  </span><br><span class="line">   time.Sleep(time.Second * <span class="number">3</span>)  </span><br><span class="line">   t.Log(<span class="string">&quot;goroutines: &quot;</span>, runtime.NumGoroutine())  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再次运行测试，结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    timeout_context_test.go:72: goroutines:  2</span><br><span class="line">--- PASS: TestAsyncTaskRunner (3.00s)</span><br><span class="line">PASS</span><br></pre></td></tr></table></figure><p>没错，使用异步 IO，在 runner 结束之后，AsyncTask2 也结束了。</p><h2 id="通过业务逻辑保证，以解决问题"><a href="#通过业务逻辑保证，以解决问题" class="headerlink" title="通过业务逻辑保证，以解决问题"></a>通过业务逻辑保证，以解决问题</h2><p>由于 go 的协程没有主协程&#x2F;子协程一说，协程一旦创建之后都会平等的接受调度与运行。因此我们并不能直接的结束调一个已创建的子协程。</p><p>于是根据上面的异步的思路，进一步封装了一个如下的异步任务限时处理器：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> TimeoutTaskHandler <span class="keyword">interface</span> &#123;  </span><br><span class="line">   HandleTimeoutTask(ctx context.Context) <span class="type">bool</span>  </span><br><span class="line">&#125;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">// TimeoutContextWrapper 一个简单的超时处理器  </span></span><br><span class="line"><span class="comment">// 处理器会在指定的最大时间内执行任务  </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TimeoutContextWrapper</span><span class="params">(ctx context.Context, timeoutSec <span class="type">int</span>, handler TimeoutTaskHandler)</span></span> &#123;  </span><br><span class="line">   <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;  </span><br><span class="line">      <span class="keyword">if</span> err := <span class="built_in">recover</span>(); err != <span class="literal">nil</span> &#123;  </span><br><span class="line">         log.Error(fmt.Errorf(<span class="string">&quot;timeout context wrapper panic: %s&quot;</span>, err))  </span><br><span class="line">      &#125;   </span><br><span class="line">   &#125;()  </span><br><span class="line">   </span><br><span class="line">   ctx, cancel := context.WithTimeout(ctx, time.Duration(timeoutSec)*time.Second)  </span><br><span class="line">   <span class="keyword">defer</span> cancel()  </span><br><span class="line">  </span><br><span class="line">   <span class="keyword">var</span> exit = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>, <span class="number">1</span>)  </span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;  </span><br><span class="line">      <span class="keyword">for</span> &#123;  </span><br><span class="line">         <span class="keyword">select</span> &#123;  </span><br><span class="line">         <span class="keyword">case</span> &lt;-ctx.Done():  </span><br><span class="line">            exit &lt;- <span class="literal">true</span>  </span><br><span class="line">            <span class="keyword">return</span>  </span><br><span class="line">  </span><br><span class="line">         <span class="keyword">default</span>:  </span><br><span class="line">            <span class="comment">// handler 的运行时间可能会超过 timeoutSec            </span></span><br><span class="line">            <span class="comment">// 所以需要通在后面配置一个超时时间，超过 timeoutSec 就退出  </span></span><br><span class="line">            haveDone := handler.HandleTimeoutTask(ctx)  </span><br><span class="line">            <span class="keyword">if</span> haveDone &#123;  </span><br><span class="line">               exit &lt;- <span class="literal">true</span>  </span><br><span class="line">               <span class="keyword">return</span>  </span><br><span class="line">            &#125;  </span><br><span class="line">         &#125;      </span><br><span class="line"> &#125;   </span><br><span class="line">   &#125;()  </span><br><span class="line">   </span><br><span class="line">   <span class="comment">// 开始一个计时器  </span></span><br><span class="line">   <span class="comment">// 超过 timeoutSec 或者 未到 timeoutSec 但是 handler 决定退出时，结束本次处理周期  </span></span><br><span class="line">   <span class="keyword">select</span> &#123;  </span><br><span class="line">   <span class="keyword">case</span> &lt;-exit:  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">   <span class="keyword">case</span> &lt;-time.After(time.Duration(timeoutSec) * time.Second):  </span><br><span class="line">      <span class="keyword">return</span>  </span><br><span class="line">   &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上代码其内部的原理和前面模拟的测试代码大同小异。要想让上面的代码按预期方式正常运行，有个逻辑需要在业务层面来保证：</p><p><code>HandleTimeoutTask()</code> 接口的实现，用来处理一个最小单位的任务，并且会在每次循环中调用。这就意味着在实现内部需要有机制来避免死循环且保证“向前”推进任务进程，同时处理时间不能超过整个调度周期的时间。</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8dov0bwxpj30lp0avq33.jpg"></p><p>此代码目前在线上运行良好，顺利的解决了一开始提出的问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>无法直接通过 kill 机制结束一个已创建的协程</li><li>建议协程中要有保障退出的机制</li><li>建议使用异部 IO，如果写成处于阻塞中，也是需要等至结束之后才能退出</li><li>避免在协程中使用死循环（或要能退出）</li><li>如果需要使用循环来处理业务，需要考虑极端情况，推荐将耗时的长任务拆分为多步执行</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Go 中的协程由于其非常易于使用的特性，在实际的使用中被广泛的应用于各个场中心。在有些场的使用可能并不是很恰当，甚至在特定的场景下定带来其他的问题。&lt;/p&gt;
&lt;h2 id=&quot;一个场景&quot;&gt;&lt;a href=&quot;#一个场景&quot; class=&quot;headerlink&quot; title=&quot;一个</summary>
      
    
    
    
    
    <category term="golang" scheme="https://www.wewx.cn/tags/golang/"/>
    
    <category term="编程" scheme="https://www.wewx.cn/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Go gRPC 客户端内存泄漏问题排查</title>
    <link href="https://www.wewx.cn/2022/11/15/go-grpc-not-releasing-memory.html"/>
    <id>https://www.wewx.cn/2022/11/15/go-grpc-not-releasing-memory.html</id>
    <published>2022-11-15T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>近期对系统进行压力测试的过程发现随着请求的增加，程序占用内存会持续增长的情况，且增长没有上限，最高占用系统内存超过 90%。</p><p>在线系统增加 <code>pprof</code> 部署后，开始 debug 与问题排查。</p><h2 id="从现象开始定位问题"><a href="#从现象开始定位问题" class="headerlink" title="从现象开始定位问题"></a>从现象开始定位问题</h2><p>很明确的问题，内存占用过高。因此更直接查看了内存分析。通过分析 <code>pprof/heap</code> 文件，得到了如下的调用堆栈，从图中可以看到， newBufWriter + NewReaderSize 共计占用了 2.5GB 内存，显得很不正常。</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85ywm8sntj30vm0u0tcm.jpg"></p><p>系统本身是一个 Web 应用，不过在其请求处理的过程中需要通过 gRPC 调用几个外部的服务，但即使是 500 的并发，占如如此多的内存也不是一个正常现象。</p><h2 id="从问题开始开析原因"><a href="#从问题开始开析原因" class="headerlink" title="从问题开始开析原因"></a>从问题开始开析原因</h2><p>既然已经找到 gRPC 客户端占用了最多的内存的证据，那就开始从 gRPC 调用代码开始分析原因。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conn, err = grpc.Dial( server, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithBlock())</span><br></pre></td></tr></table></figure><p>这是程序中初始化 gRPC 客户端的代码，简单直接，从 gRPC 官方的文档上 copy 来的。</p><p>进入 Dail 内部：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DialContext(context.Background(), target, opts...)</span><br></pre></td></tr></table></figure><p>请注意，这直接使用了默认的 Background Context. 根据文档的介绍， ctx 参数可以控制连接的取消和<strong>超时</strong>。</p><p>如果要使 ctx 的超时生效，必须要同时使用 <code>grpc.WithBlock()</code> ，因为 gRPC 默认是使用非阻塞的 http2 客户端。</p><p>那 ctx 作用是啥呢？请看官方的说法。ctx 可以用来控制 pending 的超时时间。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// In the blocking case, ctx can be used to cancel or expire the pending  </span><br><span class="line">// connection. Once this function returns, the cancellation and expiration of  </span><br><span class="line">// ctx will be noop. Users should call ClientConn.Close to terminate all the// pending operations after this function returns.</span><br></pre></td></tr></table></figure><p>那是不是并发大太，外部的服务承受不了如大的流量导致了大量 penging 状态的请求没有释放？</p><p>于是，我们将代码改成了：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ctx, cancel := context.WithTimeout(context.Background(), time.Second)  </span><br><span class="line">defer cancel()</span><br><span class="line">conn, err = grpc.DialContext(ctx, address, grpc.WithTransportCredentials(insecure.NewCredentials()), grpc.WithBlock())</span><br></pre></td></tr></table></figure><p>增加了 timeout，但将新的代码上线后，内部占用的问题并没有解决！继续看文档，此 timeout 仅作用于链接建立 block 类型的连接建立阶段。</p><h2 id="网上的答案"><a href="#网上的答案" class="headerlink" title="网上的答案"></a>网上的答案</h2><p>网上搜索的答案，几乎千篇一律的说是在 Server 端指定的 KeepAlive 参数，用于在客户端没有心跳时自动的关闭链接。</p><p><img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h86q1btnr8j316i0u045f.jpg"></p><p>服务端不是我能控制的啊，那不管服务端，可以直接在客户端直接应用 KeepAlive 吗？答案是不能。</p><p><code>keepalive.ClientParameters</code> 是客户端的 keepalive 参数配饰的 grpc.option，其注释中有明确提示：</p><blockquote><p>&#x2F;&#x2F; Make sure these parameters are set in<br>   &#x2F;&#x2F; coordination with the keepalive policy on the server, as incompatible<br>   &#x2F;&#x2F; settings can result in closing of connection.</p></blockquote><p><code>ClientParameters</code> 和<code>ServerParameters</code> 需要搭配使用，使用不当会导致链接错误的被关闭。</p><h2 id="ectd-如何使用-gRPC-Client"><a href="#ectd-如何使用-gRPC-Client" class="headerlink" title="ectd 如何使用 gRPC Client"></a>ectd 如何使用 gRPC Client</h2><p>etcd 在 v3 中全面使用了 gRPC，因此想看看在 etcd 中是如何去使用的，这里贴一下 ectd Client 初始化代码：</p><p><a href="https://github.com/etcd-io/etcd/blob/bf5c936ff1de422b48cc313435aa40ef6f2057ac/client/v3/client.go#L289">etcd&#x2F;client.go at bf5c936ff1de422b48cc313435aa40ef6f2057ac · etcd-io&#x2F;etcd · GitHub</a></p><h2 id="继续"><a href="#继续" class="headerlink" title="继续"></a>继续</h2><p>etcd 在初始化 Connection 时考虑了如 TimeOut、KeepAlive 相关的可选项，可谓是使用的标杆。参照其代对程序 Connection 的建立部分做了一些完善，不过无法仅通过 gRPC Client 的连接配置来解决这个问题，但这个问题又确确实实的发生在 gRPC Client 上，那是不是我们代码对 gRPC 使用不当？</p><p>于是，把所有调用 gRPC 的代码都找出来，共有 10 来处，一处一处的排查。</p><p>系统因需要链接多个外部的 gRPC Server，应止在程序层面有一些封装用于获取客户端。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">func GetAaaRPCClient() *grpc.Client</span><br><span class="line">func GetBbbRPCClient() *grpc.Client</span><br></pre></td></tr></table></figure><p>重新 Review 该部份代码，没有问题！且对客户端做了复用。继续 Review 余下部份，确实找到了 3 处不正确的使用：没用复用上面的 <code>GetClient</code>，而是在代码直接初始化客户端，且没有主动关闭。刚好，这三处代码码的 API 也在压测范围之内，那没错，问题就出在这了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>gRPC 客户端在其内部做了连接的优化与管理，虽并不需要用户在程序中去管理连接池，但在使用时依然需要注意：</p><ol><li>建议只为每个 Service 建立一个客户端</li><li>如果需要为每个请求建立连接，那么一定不要忘了关闭</li><li>Server 端建议配置 KeepAlive 参数，参考 <a href="https://pkg.go.dev/google.golang.org/grpc/keepalive#ServerParameters">keepalive package - google.golang.org&#x2F;grpc&#x2F;keepalive - Go Packages</a> 并在文档中告知调用方</li><li>如果 Server 明确说明了 KeepAlive，客户端在建立连接时，建议指定相关 Option，参考 <a href="https://pkg.go.dev/google.golang.org/grpc#KeepaliveParams">grpc package - google.golang.org&#x2F;grpc - Go Packages</a></li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://mycodesmells.com/post/pooling-grpc-connections">Pooling gRPC Connections - My Code Smells!</a></li><li><a href="https://stackoverflow.com/questions/56067076/grpc-connection-management-in-golang">go - GRPC Connection Management in Golang - Stack Overflow</a></li><li><a href="https://groups.google.com/g/grpc-io/c/KGlqYrTOjqI">transport.newBufWrite go grpc not releasing memory</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;近期对系统进行压力测试的过程发现随着请求的增加，程序占用内存会持续增长的情况，且增长没有上限，最高占用系统内存超过 90%。&lt;/p&gt;
&lt;p&gt;在线系统增加 &lt;code&gt;pprof&lt;/code&gt; 部署后，开始 debug 与问题排查。&lt;/p&gt;
&lt;h2 id=&quot;从现象开始定位问题</summary>
      
    
    
    
    
    <category term="gRPC" scheme="https://www.wewx.cn/tags/gRPC/"/>
    
    <category term="golang" scheme="https://www.wewx.cn/tags/golang/"/>
    
    <category term="编程" scheme="https://www.wewx.cn/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>MinIO Go Client OOM 引发的故障排查</title>
    <link href="https://www.wewx.cn/2022/09/02/minio-client-oom.html"/>
    <id>https://www.wewx.cn/2022/09/02/minio-client-oom.html</id>
    <published>2022-09-02T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本周我们系统为了提升包含多文件的任务处理效率，将原来的串行化文件处理做了一优化，改成了协程并行。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wg.Add(<span class="built_in">len</span>(fileList))</span><br><span class="line"><span class="keyword">for</span> _, pdf := <span class="keyword">range</span> fileList &#123;</span><br><span class="line">    SplitPdfFile(f)</span><br><span class="line">    wg.Done()</span><br><span class="line">&#125;</span><br><span class="line">wg.Wait()</span><br></pre></td></tr></table></figure><p>SplitPdfFile 会调用 文件服务 进行 PDF 文件处理 （按页分割、合并页码）。</p><h2 id="问题浮现"><a href="#问题浮现" class="headerlink" title="问题浮现"></a>问题浮现</h2><p>代码上线后，完了，功能完全不可用。原因是文件服务返回了 503 的错误响应。</p><h2 id="问题排查与分析过程"><a href="#问题排查与分析过程" class="headerlink" title="问题排查与分析过程"></a>问题排查与分析过程</h2><h3 id="1-为什么会-503"><a href="#1-为什么会-503" class="headerlink" title="1. 为什么会 503"></a>1. 为什么会 503</h3><p>通过 rancher 查看，服务被重启了。由于是服务直接被 k8s 重启，程序并没有记录日志，而且我们也无法进入服务器从外部查看 k8s 日志，没有进一步的信息，但其他 API 并不到返回 503，仅仅是这一个 API，于是在当时盲猜了几个原因：</p><ul><li>是有没有 recovery 的 panic 导致程序异常了</li><li>因为是文件处理，可能文件异常</li></ul><p>进一步分析与验证：</p><ul><li>程序在全局有注册 recovery，按道理所有的 painc 都会被捕获并销记录错误日志，但此情况下是没有任务日志被记录，故排除。</li><li>对于第二点，把对应文件放在本地进行处理，程序完全正常，故排除。</li></ul><p>关注点再次回到容器上，容器为什么会重启，重启的原因是什么？但我们能用的仅有 rancher，通过 google 搜索神器，我们找到在服务的 yaml 文件的 State 节点下，会记录容器上次重启的原因：<strong>OOMKilled</strong></p><h3 id="2-什么原因导致程序-OOM？"><a href="#2-什么原因导致程序-OOM？" class="headerlink" title="2. 什么原因导致程序 OOM？"></a>2. 什么原因导致程序 OOM？</h3><p>老实讲，没有想过这个不太大的文件服务会 OOM，通过观察发现程序初始启动时消耗的内存大约在 1300MB，请求部分 API 后会稳定在 1500MB 左右，而服务中的内存 limit 是 2Gi，按道理是足够的。</p><p>另外还观察到，只要请求 PDF 文件处理 API，每次请求内点点用就会增加大约 0.6 ～ 1.5g，且不会释放，多来几次就被 kill 了。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sfaox8vtj20rk01kjrh.jpg"><br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sfav9l6mj20ty01m74f.jpg"><br><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sfb1yf6aj20so01o3yn.jpg"></p><p>这个现象 100%复现，也就是可以进一步确认是 PDF 文件处理会导致 OOM</p><h3 id="3-会是不正确使用文件引发的-OOM-吗？"><a href="#3-会是不正确使用文件引发的-OOM-吗？" class="headerlink" title="3. 会是不正确使用文件引发的 OOM 吗？"></a>3. 会是不正确使用文件引发的 OOM 吗？</h3><p>这是一个 PDF 文件处理功能，那是否存在打开的文件忘关了、重复载入了文件的可能性？不排除这种可能性，于是花费了一些时间对系统的全部文件操作进行审查，顺路优化了一些代码：</p><p>Before</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">f := os.Open(path)</span><br><span class="line"></span><br><span class="line">anotherFun(f)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">anotherFun</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// code</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">defer</span> f.Close()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>After</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">f := os.Open(path)</span><br><span class="line"><span class="keyword">defer</span> f.Close()</span><br><span class="line"></span><br><span class="line">anotherFun(f)</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">anotherFun</span><span class="params">(f *os.File)</span></span> &#123;</span><br><span class="line">     <span class="comment">// code</span></span><br><span class="line">     </span><br><span class="line">     <span class="keyword">defer</span> f.Close()</span><br><span class="line">     </span><br><span class="line">     <span class="comment">// code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Before</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> fileList &#123;</span><br><span class="line">   f := os.Open(path)</span><br><span class="line">   <span class="keyword">defer</span> f.Close()</span><br><span class="line">   </span><br><span class="line">   <span class="comment">// code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>After</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> _, v := <span class="keyword">range</span> fileList &#123;</span><br><span class="line">    f := os.Open(path)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// code</span></span><br><span class="line">    _ = f.Close()</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>仔细排查文件操作之后，所有文件使用都已规范、文件关闭时机都很合理、也不存在重复读入的问题，但在线上问题依旧！</p><h3 id="4-上神器-pprof"><a href="#4-上神器-pprof" class="headerlink" title="4. 上神器 pprof"></a>4. 上神器 pprof</h3><p>借助pprof，我们观察到在本机运行，即使是 50 个并发循环 10 次这样量级内存占用依然是稳定的！并不会像服务器上一样出现 OOM 并引起崩溃的情况。</p><p>程序启动</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sfa7zki5j21800j0n27.jpg"></p><p>并发请求后</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sfagqbglj215o0is76u.jpg"></p><p>由此基本可以确定问题仅出现在线上环境，于是把线上的 heap 信息down 到本地并使用 pprof 时行分析，最后发现是 MinIO Client 占用了大量内存没有释放。</p><h3 id="5-为啥在本地没有复现？"><a href="#5-为啥在本地没有复现？" class="headerlink" title="5. 为啥在本地没有复现？"></a>5. 为啥在本地没有复现？</h3><p>定位到问大概的问题，我们再回到本地，分析本地不能复现的原因。经过一遍一遍撸代码，发现在本地运行模式和线上有一些差异。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h5sf94dstyj20u00uh760.jpg"></p><p>如果程序运行在本机模式下，程序并没有经过 MinIO Client，而是直连的 OSS，也就异致问题不能在本机进行复现。</p><h3 id="6-最后，再来深究一下-MinIO-Client-为什么会导致-OOM？"><a href="#6-最后，再来深究一下-MinIO-Client-为什么会导致-OOM？" class="headerlink" title="6. 最后，再来深究一下 MinIO Client 为什么会导致 OOM？"></a>6. 最后，再来深究一下 MinIO Client 为什么会导致 OOM？</h3><p>如果使用 “minio client oom” 在 google 进行搜索，会发现已有相关记录而并非是个例。 大家遇到的问题和我们是一样的。</p><p>OOM 其实是由 mc.PutObject() 这个函数触发，其第二个参数 size 如果传递 -1 则会引起 OOM。</p><p>参数 Size 的作用是指定要上传的文件大小，MinIO 会根据不同的文件大小使用不同的上传策略。对于没有指定大不的文件（-1），MinIO Client 会认为该文件的大小为 5TB，并以 5G 的分片大小进行上传，每次会将该片的全部字节读入内存中，那如果如时操作多个文件，就会导致内存耗尽。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PutObject creates an object in a bucket.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// You must have WRITE permissions on a bucket to create an object.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  - For size smaller than 16MiB PutObject automatically does a</span></span><br><span class="line"><span class="comment">//    single atomic PUT operation.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  - For size larger than 16MiB PutObject automatically does a</span></span><br><span class="line"><span class="comment">//    multipart upload operation.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  - For size input as -1 PutObject does a multipart Put operation</span></span><br><span class="line"><span class="comment">//    until input stream reaches EOF. Maximum object size that can</span></span><br><span class="line"><span class="comment">//    be uploaded through this operation will be 5TiB.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//    WARNING: Passing down &#x27;-1&#x27; will use memory and these cannot</span></span><br><span class="line"><span class="comment">//    be reused for best outcomes for PutObject(), pass the size always.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> Upon errors during upload multipart operation is entirely aborted.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span></span> PutObject(ctx context.Context, bucketName, objectName <span class="type">string</span>, reader io.Reader, objectSize <span class="type">int64</span>,</span><br><span class="line">   opts PutObjectOptions) (info UploadInfo, err <span class="type">error</span>) &#123;</span><br></pre></td></tr></table></figure><p>其实，PutObject 方法原型的注释中，Waring 有提醒我们，使用该方法时都需要传递文件尺寸，奈何一开始没有注意到，从而掉入到了坑里。</p><h3 id="7-解决方法"><a href="#7-解决方法" class="headerlink" title="7. 解决方法"></a>7. 解决方法</h3><p>找到了问题，那解决方案也很简单了。在 size 处传递正确的文件尺寸即可。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>从业务上考虑我们要设置多大的文件</li><li>根据文件 Size 上限、最多支持 10, 000 part 、并发度控制，容器内存大小等因素来指定 part 大小</li><li>minio 需要根据 part size 的大小来确定最高的并发度来防止容器 OOM，并且需要控制到 minio 驱动层，而不是业务层</li><li>虽然 Minio S3 接口不支持流式，但支持分片，所以上传大文件的时候仍然需要用流式，而不是把大文件都加载到内存才开始上传到 Minio</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;本周我们系统为了提升包含多文件的任务处理效率，将原来的串行化文件处理做了一优化，改成了协程并行。&lt;/p&gt;
&lt;figure class=&quot;hi</summary>
      
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Docker" scheme="https://www.wewx.cn/tags/Docker/"/>
    
    <category term="MinIO" scheme="https://www.wewx.cn/tags/MinIO/"/>
    
  </entry>
  
  <entry>
    <title>Go 实时日志收集</title>
    <link href="https://www.wewx.cn/2022/08/12/golang-log-collection.html"/>
    <id>https://www.wewx.cn/2022/08/12/golang-log-collection.html</id>
    <published>2022-08-12T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>通常基础系统都会自动处理与收集日志，并不太需要应用来收集。但利用 go 的并发与携程能力，要实现实时的日志收集也是非常简单。</p><p>功能设计</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h54ajve0rlj20qf0d3q4e.jpg" alt="日志收集程序设计"></p><ul><li>主程序向指定的日志文件记录日志</li><li>收集程序独立于主程序之外，通过实时监控程序日志的方式即时读取新写入的日志</li><li>在读取到日志行之后，将其通过 channel 传送给日志处理进程</li><li>处理完成后视需要存储到 <code>es / logstash / influxdb</code></li></ul><p>优点</p><p>日志收集程序独立于主程序之外运行，对程序无侵入性。</p><p>实现</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> logCollection</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">   <span class="string">&quot;bufio&quot;</span></span><br><span class="line">   <span class="string">&quot;encoding/json&quot;</span></span><br><span class="line">   <span class="string">&quot;errors&quot;</span></span><br><span class="line">   <span class="string">&quot;io&quot;</span></span><br><span class="line">   <span class="string">&quot;os&quot;</span></span><br><span class="line">   <span class="string">&quot;strings&quot;</span></span><br><span class="line">   <span class="string">&quot;syscall&quot;</span></span><br><span class="line">   <span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> logIno <span class="type">uint64</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> logCount <span class="type">int</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> LogLine <span class="keyword">struct</span> &#123;</span><br><span class="line">   Level      <span class="type">string</span>  <span class="string">`json:&quot;level&quot;`</span></span><br><span class="line">   TS         <span class="type">float64</span> <span class="string">`json:&quot;ts&quot;`</span></span><br><span class="line">   Caller     <span class="type">string</span>  <span class="string">`json:&quot;caller&quot;`</span></span><br><span class="line">   Msg        <span class="type">string</span>  <span class="string">`json:&quot;msg&quot;`</span></span><br><span class="line">   StackTrace <span class="type">string</span>  <span class="string">`json:&quot;stacktrace&quot;`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getFileIno</span><span class="params">(path <span class="type">string</span>)</span></span> <span class="type">uint64</span> &#123;</span><br><span class="line">   fileinfo, _ := os.Stat(path)</span><br><span class="line">   stat, ok := fileinfo.Sys().(*syscall.Stat_t)</span><br><span class="line">   <span class="keyword">if</span> !ok &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">return</span> stat.Ino</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">openLog</span><span class="params">(path <span class="type">string</span>, rc <span class="keyword">chan</span> []<span class="type">byte</span>)</span></span> &#123;</span><br><span class="line">   <span class="keyword">var</span> f *os.File</span><br><span class="line">   <span class="keyword">var</span> err <span class="type">error</span></span><br><span class="line"></span><br><span class="line">   <span class="comment">// create file if not exists</span></span><br><span class="line">   <span class="keyword">if</span> _, err = os.Stat(path); errors.Is(err, os.ErrNotExist) &#123;</span><br><span class="line">      f, err = os.Create(path)</span><br><span class="line">      <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">         <span class="built_in">panic</span>(err)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      f, err = os.Open(path)</span><br><span class="line">      <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">         <span class="built_in">panic</span>(err)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   logIno = getFileIno(path)</span><br><span class="line">   <span class="keyword">if</span> logIno == <span class="number">0</span> &#123;</span><br><span class="line">      <span class="built_in">panic</span>(errors.New(<span class="string">&quot;open log file failed&quot;</span>))</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">(f *os.File)</span></span> &#123;</span><br><span class="line">      _ = f.Close()</span><br><span class="line">   &#125;(f)</span><br><span class="line"></span><br><span class="line">   f.Seek(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">   buf := bufio.NewReader(f)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> &#123;</span><br><span class="line">      <span class="comment">// check file ino</span></span><br><span class="line">      <span class="comment">// if changed, reopen file</span></span><br><span class="line">      <span class="keyword">if</span> logIno != getFileIno(path) &#123;</span><br><span class="line">         variable.Logger.Error(<span class="string">&quot;openLog logIno != new : &quot;</span>, logIno)</span><br><span class="line">         _ = f.Close()</span><br><span class="line"></span><br><span class="line">         f, err = os.Open(path)</span><br><span class="line">         <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            variable.Logger.ErrorF(<span class="string">&quot;open log file failed: %s\n&quot;</span>, err)</span><br><span class="line">            <span class="built_in">panic</span>(err)</span><br><span class="line">         &#125;</span><br><span class="line"></span><br><span class="line">         logIno = getFileIno(path)</span><br><span class="line">         <span class="keyword">continue</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      line, err := buf.ReadBytes(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">      <span class="keyword">switch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> err == io.EOF:</span><br><span class="line">         time.Sleep(time.Second)</span><br><span class="line">      <span class="keyword">case</span> err != <span class="literal">nil</span>:</span><br><span class="line">         <span class="keyword">break</span></span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">         rc &lt;- line[:<span class="built_in">len</span>(line)<span class="number">-1</span>]</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Write</span><span class="params">(path <span class="type">string</span>)</span></span> &#123;</span><br><span class="line">   <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">      <span class="keyword">for</span> &#123;</span><br><span class="line">         time.Sleep(time.Second)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;()</span><br><span class="line"></span><br><span class="line">   c := <span class="built_in">make</span>(<span class="keyword">chan</span> []<span class="type">byte</span>)</span><br><span class="line">   <span class="keyword">go</span> openLog(path, c)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> &#123;</span><br><span class="line">      line := &lt;-c</span><br><span class="line">      process(line)</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">process</span><span class="params">(line []<span class="type">byte</span>)</span></span> &#123;</span><br><span class="line">   <span class="keyword">var</span> logLine LogLine</span><br><span class="line">   err := json.Unmarshal(line, &amp;logLine)</span><br><span class="line">   <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> logLine.Level == <span class="string">&quot;debug&quot;</span> || logLine.Level == <span class="string">&quot;info&quot;</span> &#123;</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// 精简 trace</span></span><br><span class="line">   traces := strings.Split(logLine.StackTrace, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">   <span class="keyword">if</span> <span class="built_in">len</span>(traces) &gt; <span class="number">2</span> &#123;</span><br><span class="line">      traces = traces[<span class="number">2</span>:]</span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">len</span>(traces) &gt; <span class="number">3</span> &#123;</span><br><span class="line">         traces = traces[:<span class="number">3</span>]</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   write(&amp;logLine)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">write</span><span class="params">(log *LogLine)</span></span> &#123;</span><br><span class="line">   <span class="comment">// write to es</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意上面代码中的一个小细节：</p><p>在我们系统中，主程只负责向 <code>app.log</code> 写日志，但 <code>app.log</code> 会在每天凌晨被重命名为 <code>app_2022-08-10.log</code> 以实现日志分割。</p><p>那么如何检测文件被移动呢？</p><p>上面代码中的实现是通过 <code>file index no, fio</code> 来判断，如果打开的 <code>app.log</code> fio 与磁盘上 <code>app.log</code> 文件的 fio 不一致，则认为是创建了新的日志文件，此时再重新打开日志即可。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;通常基础系统都会自动处理与收集日志，并不太需要应用来收集。但利用 go 的并发与携程能力，要实现实时的日志收集也是非常简单。&lt;/p&gt;
&lt;p&gt;功能设计&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://tva1.sinaimg.cn/large/e6c9d24egy1h54a</summary>
      
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="golang" scheme="https://www.wewx.cn/tags/golang/"/>
    
    <category term="并发编程" scheme="https://www.wewx.cn/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Laravel 应用从 MySQL 迁移到 SQLite</title>
    <link href="https://www.wewx.cn/2022/06/22/laravel-from-mysql-migrate-to-sqlite.html"/>
    <id>https://www.wewx.cn/2022/06/22/laravel-from-mysql-migrate-to-sqlite.html</id>
    <published>2022-06-22T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>阿里云提醒 RDS 要续费了，几大百一年但实际上现在只有几个小型的应用在用 MySQL。疫情之下，本着开源节流的原则，打算把 MySQL 给替换成 SQLite 以便省点银子。</p><p>之前对于 SQLite 也就是了解的程度但并没有实际使用，应此在正式切换之前还需要做一些准备工作。</p><p>SQLite 和 MySQL 类似，都是一种 关系数据库管理系统 （RDBMS，Relational Database Management System）。以数据表作为基础的数据存储系统。</p><h2 id="SQLite-的优缺点"><a href="#SQLite-的优缺点" class="headerlink" title="SQLite 的优缺点"></a>SQLite 的优缺点</h2><blockquote><p>Small. Fast. Reliable.</p></blockquote><p>SQLite 是一款 C 编写的关系数据库。正如其名，SQLite 并非是作为一个独立的进程运行，也不需要使用特这的通信息协议与应用程序连接，而是直接作为应用程序的一部分随程序发布，这样的特性使 SQLite 非常的轻量级与易于使用，在手机、电脑、嵌入式设备、应用内嵌数据库等方面有着非常广泛的应用。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3h1e224qkj20bb034q2u.jpg" alt="https://www.sqlitetutorial.net/what-is-sqlite/"></p><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>零配置，易使用</li><li>可跨平台。SQLite 基于特定格式的单个文件，可移动性和跨平台特性好</li><li>备份容易。直接使用 <code>cp</code> 复制数据库文件即可</li><li>开方测试方便。基于 SQLite 的自<a href="https://www.sqlite.org/selfcontained.html">包含特性</a>，使其的以来非常少，在开发过程中可作为替代手段，待上线后有需要再改为其他 RDBMS</li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>没有用户系统</li><li>不支持网络访问</li><li>不适用于大型程序</li><li>提升性能的手段有限</li></ul><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>嵌入式设备 </li><li>物联设备</li><li>作为 excel 的替代</li><li>小型应用</li><li>小量数据分析</li><li>数据缓存 </li><li>开发和测试阶段的临时方案</li><li>教学目的</li></ul><h2 id="MySQL-的优缺点"><a href="#MySQL-的优缺点" class="headerlink" title="MySQL 的优缺点"></a>MySQL 的优缺点</h2><p>MySQL 是当前最为热门的关系数据库（RDBMS），目前世界上大多数应用都在使用它。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3h1iy6ys1j20gs06m0sw.jpg" alt="https://www.sqlitetutorial.net/what-is-sqlite/"></p><h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><ul><li>功能强大</li><li>用户管理功能</li><li>内置更多的安全功能</li><li>更精细的事务和锁机制</li><li>更好的并发性能</li><li>支持网络访问</li></ul><h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul><li>数据跨平台性差</li><li>可靠性问题</li><li>发展停滞，尽管 MySQL 仍是开源软件，但自从被收购之后发展已放缓</li></ul><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li>分布式协作</li><li>大流量网站或中型应用系统</li><li>事务支持的程序</li><li>需要大量数据写入</li><li>存储更大规模数据量</li></ul><h2 id="Laravel-应用替换"><a href="#Laravel-应用替换" class="headerlink" title="Laravel 应用替换"></a>Laravel 应用替换</h2><p><code>mysql-to-sqlite3</code> 是一款 Python 的程序，可以将 MySQL 的数据库转换为 SQLite3 格式的数据库。</p><h3 id="安装并运行转换"><a href="#安装并运行转换" class="headerlink" title="安装并运行转换"></a>安装并运行转换</h3><pre><code>pip install mysql-to-sqlite3mysql2sqlite --helpmysql2sqlite -f ./sqlite.db \-d mysql数据库名称 \-u mysql数据库用户名 \--mysql-password mysql数据库密码 \-h mysql数据库地址</code></pre><p>上面的命令可以生成 <code>sqlite.db</code> 文件，直接使用即可。</p><h3 id="调整-Laravel-配置"><a href="#调整-Laravel-配置" class="headerlink" title="调整 Laravel 配置"></a>调整 Laravel 配置</h3><pre><code>DB_CONNECTION=sqliteDB_DATABASE=/absolute/path/to/database.sqlite</code></pre><p>直接修改 <code>.env</code> 中的 MYSQL 配置，参考上面的的就行。注意 <code>database.sqlite</code> 文件需要有可写权限。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;阿里云提醒 RDS 要续费了，几大百一年但实际上现在只有几个小型的应用在用 MySQL。疫情之下，本着开源节流的原则，打算把 MySQL 给替换成 SQLite 以便省点银子。&lt;/p&gt;
&lt;p&gt;之前对于 SQLite 也就是了解的程度但并没有实际使用，应此在正式切换之前还需要</summary>
      
    
    
    
    
    <category term="Laravel" scheme="https://www.wewx.cn/tags/Laravel/"/>
    
  </entry>
  
  <entry>
    <title>威联通NAS进阶玩法之 Portainer</title>
    <link href="https://www.wewx.cn/2022/06/19/Portainer-of-QNAP-NA-advanced-gameplay.html"/>
    <id>https://www.wewx.cn/2022/06/19/Portainer-of-QNAP-NA-advanced-gameplay.html</id>
    <published>2022-06-19T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>Portainer 是一个可视化的容器镜像的图形管理工具，利用Portainer 可以轻松构建，管理和维护Docker环境。 而且完全免费，基于容器化的安装方式，方便高效部署。</p><p>官网地址：<a href="https://www.portainer.io/">https://www.portainer.io/</a></p><h3 id="登录NAS"><a href="#登录NAS" class="headerlink" title="登录NAS"></a>登录NAS</h3><p>首先在 NAS 控制面板开启 SSH 登录功能。接着使用 <code>admin</code> 账号密码登录（只能使用 admin)。</p><h3 id="搜索镜像"><a href="#搜索镜像" class="headerlink" title="搜索镜像"></a>搜索镜像</h3><p>docker search portainer</p><h3 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h3><p>docker pull portainer&#x2F;portainer</p><h3 id="运行镜像"><a href="#运行镜像" class="headerlink" title="运行镜像"></a>运行镜像</h3><pre><code>docker run -d -p 9001:9000 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v /portainer_data:/data/portainer/portainer portainer/portainer</code></pre><p>参数介绍：</p><ul><li>“-d”代表”后台运行容器，并返回容器ID”</li><li>“-p”代表”容器内部端口随机映射到主机的高端口”，前面的9000是容器默认端口，后面的9000是安装后映射的端口（冒号前后）</li><li>“–name” 代表容器的名字</li><li>“–restart always”代表总是Docker启动后容器自动启动</li><li>“-v”表示路径映射，portainer的路径映射用默认就行，如果为了方便迁移可以映射到Nas的实体路径</li></ul><h3 id="访问Portainer容器"><a href="#访问Portainer容器" class="headerlink" title="访问Portainer容器"></a>访问Portainer容器</h3><pre><code>http://&lt;你的NAS IP地址&gt;:9001</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Portainer 是一个可视化的容器镜像的图形管理工具，利用Portainer 可以轻松构建，管理和维护Docker环境。 而且完全免费，基于容器化的安装方式，方便高效部署。&lt;/p&gt;
&lt;p&gt;官网地址：&lt;a href=&quot;https://www.portainer.io/&quot;&gt;</summary>
      
    
    
    
    
    <category term="NAS" scheme="https://www.wewx.cn/tags/NAS/"/>
    
  </entry>
  
  <entry>
    <title>我的长沙初印象</title>
    <link href="https://www.wewx.cn/2022/06/03/first-impressions-of-changsha.html"/>
    <id>https://www.wewx.cn/2022/06/03/first-impressions-of-changsha.html</id>
    <published>2022-06-03T02:36:48.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>4月底我们团队确定了要去长沙出差的计划，对于这种长达一个月、在陌生城市出差，虽拒我心底是拒绝的但又无可奈何，基于这种抵触的情绪订了5.2号伴晚的车票。从深圳出发历经3个半小时高铁，到达住处大约是晚上10点，不算晚。</p><h3 id="好吃不贵"><a href="#好吃不贵" class="headerlink" title="好吃不贵"></a>好吃不贵</h3><p>饿了！<br>晚饭还没吃，可能是真饿也或许是馋长沙美食！下楼向大堂前台问了问周边商业分布情况便小跑着向附近一条小吃街而去，去寻找长沙同事口中盛赞的美味。然而，在那条不长的街道上只有少数几个小吃店还在营业着，其他大多已经休息。走至街口最近的一家米粉店推门而入，看到墙上的菜单，价格是7-13元之间。这价格让人感觉仿佛回到10年前。<br>“老板， 一碗杀猪粉”。等待了几分钟，端上来一大碗，猪杂、肉量还挺足，一碗干光不仅赶走深夜的饥饿感，还认我收获了大大的满足感与城市生活的幸福感。</p><h3 id="茶颜悦色"><a href="#茶颜悦色" class="headerlink" title="茶颜悦色"></a>茶颜悦色</h3><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3fzyangmuj20u00mignh.jpg" alt="茶颜悦色"><br>初到长沙就直奔茶颜悦色而去，但其实它根本不用找。街上几百米就有一家。但又似乎每家店都需要等待很久，也是，毕竟好看又好喝的奶茶谁能拒绝。<br>这一个月，几乎每天一杯，我要离开之前把 1 年的茶颜都喝掉！</p><h3 id="连着下40天雨"><a href="#连着下40天雨" class="headerlink" title="连着下40天雨"></a>连着下40天雨</h3><p>“清时时节雨纷纷”。但我们是5月来的长沙啊，整整2个星期了一直在下雨，都给我整蒙了，不过2个星期还不是真相啊，听同事说下了接近40天了快。。。</p><p>这可真是有点吓人，得要买多少衣服才够换？我只带了2身衣服，想逃了。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3f6kfxmz4j20ic0dr3zc.jpg" alt="这个图没有大桥"></p><h3 id="司机真的不会让行人"><a href="#司机真的不会让行人" class="headerlink" title="司机真的不会让行人"></a>司机真的不会让行人</h3><p>或许是习惯了深圳路口的车让人，所以在过马路口时，见车还远就打算走来着。但是刚走上斑马线，急速驶来的汽车根本就没减速的意思，吓得我们不得不后退让行。<br>事后和本地同事说起，他们都觉得这很正常。这在长沙少有“车认人”的，因此提醒我们过马路一定得小心。<br>但是… 《道路交通安全法》规定在以下四种情形车需礼让行人啊：一是当路口的右转弯车道和人行横道都是绿灯时，机动车要停车让行人先行;二是在路中遇到人行横道(没有信号灯控制)而行人正在通过人行横道或正欲通过时，机动车同样要停车让行人先行;三是在没有交通信号的道路上，机动车遇行人横过道路，还是应当避让;四是机动车行经人行横道时要减速，遇行人迟疑或左顾右盼不敢过马路，要主动示意行人先行。 </p><h3 id="辣出眼泪"><a href="#辣出眼泪" class="headerlink" title="辣出眼泪"></a>辣出眼泪</h3><p>辣！辣！辣！这是个无辣不欢的省份！<br>第一周末，同事接接待了我们，请大家吃了2022的第一顿小龙虾，做法很多，但我只能感到一种口味：辣！</p><p>某日，在老长沙同事的带领下我们去走街串巷探索外地人可能并不知道隐藏店铺。其中有一家叫“盟重”的烧烤店。对，就是《热血传奇》中的盟重！猜想老板一定是一个资深且高端的传奇玩家，整个店铺装修得很有沙漠风格，就连菜品名称也是“半月”和“烈火”  ！同事照顾我们这些从广东而去的小伙伴特地点了“微辣”烧烤，聊了会，菜品上桌，开始撸串。</p><p>斯！辣！ 长沙朋友和有我们，对于“微辣”完全是两种不同的理解，他们吃着平平淡淡，但我一口下去就爆泪…惹不起！</p><h3 id="幸福感"><a href="#幸福感" class="headerlink" title="幸福感"></a>幸福感</h3><p>连续13年获评“中国最具幸福感城市”，长沙的幸福感被当地同事称道！<br>长沙给生活在这座城市里的人带来最大的幸福感，就是较高的收入性价比、便利的交通和丰富的文化生活。<br>除此之外，长沙也是千年古城、风韵之都、时光老城、美食之城…</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h3fzwuhflhj20fa0mvjt8.jpg" alt="长沙"></p><p>长沙，爱了！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;4月底我们团队确定了要去长沙出差的计划，对于这种长达一个月、在陌生城市出差，虽拒我心底是拒绝的但又无可奈何，基于这种抵触的情绪订了5.2号伴晚的车票。从深圳出发历经3个半小时高铁，到达住处大约是晚上10点，不算晚。&lt;/p&gt;
&lt;h3 id=&quot;好吃不贵&quot;&gt;&lt;a href=&quot;#好</summary>
      
    
    
    
    
    <category term="长沙" scheme="https://www.wewx.cn/tags/%E9%95%BF%E6%B2%99/"/>
    
  </entry>
  
  <entry>
    <title>Web 前端直接渲染 Office 格式文档的几种方案</title>
    <link href="https://www.wewx.cn/2022/05/30/office-docs-online-preview.html"/>
    <id>https://www.wewx.cn/2022/05/30/office-docs-online-preview.html</id>
    <published>2022-05-30T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>在一些中台系统中或管理后台系统中，在线预览 Office 文档是个比较常见的需求，奈何浏览器的支持有限在做相关功能时踩了一些坑。</p><h2 id="通用解决方案"><a href="#通用解决方案" class="headerlink" title="通用解决方案"></a>通用解决方案</h2><h3 id="通过-PDF-格式预览"><a href="#通过-PDF-格式预览" class="headerlink" title="通过 PDF 格式预览"></a>通过 PDF 格式预览</h3><p>现在注流的浏览器已经支持了 PDF 文件的在线预览，但是对于 word &#x2F; excel 等格式文件，浏览器的还没有提供直接的支持。应此在需要预览 word 或 excel 文件时，可以考虑先将其转换为 PDF 文件，再通过浏览器的能力渲染。</p><p>渲染 PDF 文件非常简单，比较常见的有下面 2 种方式：</p><ul><li>链接</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>Open a PDF file <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">&quot;/uploads/media/example.pdf&quot;</span>&gt;</span>example<span class="tag">&lt;/<span class="name">a</span>&gt;</span>.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br></pre></td></tr></table></figure><p>点击链接，浏览器会新一个 Tab 来打开 PDF 文件进行预览。</p><ul><li>在 html 中通过 iframe 来渲染</li></ul><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">iframe</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">src</span>=<span class="string">&quot;/uploads/media/example.pdf&quot;</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">width</span>=<span class="string">&quot;100%&quot;</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">height</span>=<span class="string">&quot;500px&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2 种方式都是基于浏览器内置能力实现，有点和缺点也都比较明显：</p><ul><li>优点：自带“打印”，“搜索”，“翻页”等功能，强大且实现非常简单方便</li><li>缺点：不同浏览器的pdf工具样式不一，且无法满足个性化需求，比如：禁止打印，下载等</li></ul><h3 id="PDF-js"><a href="#PDF-js" class="headerlink" title="PDF.js"></a>PDF.js</h3><p><a href="https://mozilla.github.io/pdf.js">PDF.js</a> 由 mozilla 开发并使用 apache 许可开源发布的工具库。其基于HTML5技术构建，用于展示可移植文档格式的文件(PDF)，它可以在现代浏览器中使用且无需安装任何第三方插件。简单的 demo 如下，详细使用方法可参考项目官网。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">canvas</span> <span class="attr">id</span>=<span class="string">&quot;pdf-canvas&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">canvas</span>&gt;</span></span><br><span class="line"></span><br><span class="line">var url = &#x27;Helloworld.pdf&#x27;;</span><br><span class="line"></span><br><span class="line">PDFJS.getDocument(url).then((pdf) =&gt; &#123;</span><br><span class="line">    return pdf.getPage(1);</span><br><span class="line">&#125;).then((page) =&gt; &#123;</span><br><span class="line">    // 设置展示比例</span><br><span class="line">    var scale = 1.5;</span><br><span class="line">    // 获取pdf尺寸</span><br><span class="line">    var viewport = page.getViewport(scale);</span><br><span class="line">    // 获取需要渲染的元素</span><br><span class="line">    var canvas = document.getElementById(&#x27;pdf-canvas&#x27;);</span><br><span class="line">    var context = canvas.getContext(&#x27;2d&#x27;);</span><br><span class="line">    canvas.height = viewport.height;</span><br><span class="line">    canvas.width = viewport.width;</span><br><span class="line">    </span><br><span class="line">    var renderContext = &#123;</span><br><span class="line">        canvasContext: context,</span><br><span class="line">        viewport: viewport</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    page.render(renderContext);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h3 id="通过在线预览服务"><a href="#通过在线预览服务" class="headerlink" title="通过在线预览服务"></a>通过在线预览服务</h3><p>微软和 Google 都提供了免费的文档在线预览服务，通过该服务我们可以非常方便的实便在 web 中预览文件，但是这种方式的缺点在于，文档必需为公网可访问，否则无法预览。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 微软 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">iframe</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">src</span>=<span class="string">&#x27;https://view.officeapps.live.com/op/view.aspx?src=http://a.com/b.xls&#x27;</span> </span></span><br><span class="line"><span class="tag">    <span class="attr">width</span>=<span class="string">&#x27;100%&#x27;</span> <span class="attr">height</span>=<span class="string">&#x27;100%&#x27;</span> <span class="attr">frameborder</span>=<span class="string">&#x27;1&#x27;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Google --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">:src</span>=<span class="string">&quot;&#x27;https://docs.google.com/viewer?url=&quot;</span><span class="attr">fileurl</span>&quot;&gt;</span><span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure><p>除了在公网使用微软服务，或将 word 或 excel 文件转为 PDF 外，还有没有其它的方式呢？</p><h2 id="sheet-js"><a href="#sheet-js" class="headerlink" title="sheet.js"></a>sheet.js</h2><p><a href="https://github.com/SheetJS/sheetjs">SheetJS</a> 和 pdf.js 类似，基于现在流行的 HTML5 技术构建，可以直接在web 页面中通过 js 或 ts 渲染表格。</p><h2 id="word-文件"><a href="#word-文件" class="headerlink" title="word 文件"></a>word 文件</h2><p>目前对于 word 文件还是无能为力。</p><h2 id="商业服务"><a href="#商业服务" class="headerlink" title="商业服务"></a>商业服务</h2><p>在企业市场，将文档转为共网可访问的文件，显然是不行的，因此催生了众多的商业服务为企业提供相关的解决方案。这里列举几个常见的平台：</p><ul><li>XDOC文档预览云服务 <a href="https://view.xdocin.com/">https://view.xdocin.com/</a>    支持私有化</li><li>永中 <a href="https://www.yozodcs.com/">https://www.yozodcs.com/</a>   支持私有化</li><li>IDOC <a href="https://www.idocv.com/docs.html">https://www.idocv.com/docs.html</a>  支持私有化</li><li>文档服务 DOC <a href="https://cloud.baidu.com/product/doc.html?track=cp:nsem%7Cpf:pc%7Cpp:doc%7Cpu:long%7Cci:%7Ckw:118945">https://cloud.baidu.com/product/doc.html?track=cp:nsem|pf:pc|pp:doc|pu:long|ci:|kw:118945</a></li><li>Wps <a href="https://wwo.wps.cn/docs/introduce/">https://wwo.wps.cn/docs/introduce/</a></li></ul><p>总结一下，对于可公开的文档，基于微软的在线预览服务，简单便捷。对于不可公开的文档，可以考虑将其转换为通用的 PDF 格式。如果有更多的要求，可以购买相关的服务。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在一些中台系统中或管理后台系统中，在线预览 Office 文档是个比较常见的需求，奈何浏览器的支持有限在做相关功能时踩了一些坑。&lt;/p&gt;
&lt;h2 id=&quot;通用解决方案&quot;&gt;&lt;a href=&quot;#通用解决方案&quot; class=&quot;headerlink&quot; title=&quot;通用解决方案&quot;&gt;</summary>
      
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="前端" scheme="https://www.wewx.cn/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>深入分析 MinIO Gateway 存储网关</title>
    <link href="https://www.wewx.cn/2022/05/10/minio-gateway.html"/>
    <id>https://www.wewx.cn/2022/05/10/minio-gateway.html</id>
    <published>2022-05-10T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>业务系统因文件存储需求，需新增通用文件服务，除公有云上使用，还要满足私用化场景，几番对比之最终选择基于 MinIO 构建，一来在公有上将其用作存储网关，在私有化环境中直接用作对象存储服务。</p><p>MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。兼容 AWS S3 like API，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器&#x2F;虚拟机镜像等，而一个对象文件可以是任意大小，最大支持5T。</p><p>MinIO 除了是对象存储服务外，它还内置了一个存对网关 MinIO Gateway，后端支持多种 S3 like 类型的存储系统，像 S3、NAS、HDFS、Google Cloud对象存储等。</p><p>由于 MinIO 存储网关的存在，使用系统具备较好的兼容性和可移植性。在必要时，可以非常方便的从 S3 迁移到 Google Cloud  的对象存储，而不用调整系统，甚至是使用在后端同时使用多个厂商存储服务实现多云混合，再或者部署多个网关实现分布式以提供更为强大的并发能力。</p><p>MinIO 支持格式众多的云存储服务，不过在支持的产品列表中却没有我们常用的阿里云 OSS 或是腾讯云的储存服务，不得不说多少有些遗憾。</p><p>目前 MinIO 官网的支持清单：</p><ul><li>Azure</li><li>GCS</li><li>S3</li><li>HDFS</li></ul><h2 id="MinIO-Alibaba-OSS"><a href="#MinIO-Alibaba-OSS" class="headerlink" title="MinIO Alibaba OSS"></a>MinIO Alibaba OSS</h2><p>MinIO 在早期曾集成过 Alibaba OSS 的代理理服务，后因 Alibaba OSS 官方SDK 的 License 问题被 MinIO 移除。</p><p>时隔一年，虽 License 修复但重新申请合并的请求被拒绝了，此后 MinIO 官方也没有再支持国内主流厂商的计划。具体细节可查看 MinIO issue 中的相关讨论。</p><h2 id="MinIO-网关"><a href="#MinIO-网关" class="headerlink" title="MinIO 网关"></a>MinIO 网关</h2><p>MinIO 作为网关，主要有以下几个的功能。<br>首先，MinIO 网关能够屏蔽后台各存储产品的差异，便客户端提供统一的接口，使用 MinIO Clinent 即可在多种云之间切换。<br>其次，MinIO 网关能够向后端的云存储产品增加 MinIO 独有的一些功能，比如磁盘缓存、资源浏览器功能。<br>再次，通过部署多个网关，可实现分布的存储存架构，提升程序的可用性。</p><p>前面提到在现行的版本中，只是内置少量几个产品的Gateway，若要使用其他 OSS 或其或一些非 S3 like 的产品需要动手去扩展。</p><h3 id="Gateway的设计"><a href="#Gateway的设计" class="headerlink" title="Gateway的设计"></a>Gateway的设计</h3><p>Gateway 分为 GatewayLayer 和 ObjectLayer 及  Credential 2层。 GatewayLayer 包含网关名称和认证信息，而ObjectLayer 则是各对象存储的一个抽象。</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h22cnt3q27j216q0i80tq.jpg"><br>￼￼<br>整个 MinIO Gateway 模块呈现一种分层的架构，如下图</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h22d5idcx6j20u010n76j.jpg"></p><h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h4><p>网关的接口其实比较简单的，就 2 个方法，获取名称和实例化 Object Layer.</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Gateway represents a gateway backend.</span></span><br><span class="line"><span class="keyword">type</span> Gateway <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Name returns the unique name of the gateway.</span></span><br><span class="line">Name() <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// NewGatewayLayer returns a new  ObjectLayer.</span></span><br><span class="line">NewGatewayLayer(creds madmin.Credentials) (ObjectLayer, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>ObjectLayer 接口由于是对象存储产品的抽象层，所以方法比较多，涵盖了 S3 like 的 Bucket 和 Object 的所有操作。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ObjectLayer implements primitives for object API layer.</span></span><br><span class="line"><span class="keyword">type</span> ObjectLayer <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Locking operations on object.</span></span><br><span class="line">NewNSLock(bucket <span class="type">string</span>, objects ...<span class="type">string</span>) RWLocker</span><br><span class="line"></span><br><span class="line"><span class="comment">// Storage operations.</span></span><br><span class="line">Shutdown(context.Context) <span class="type">error</span></span><br><span class="line">NSScanner(ctx context.Context, bf *bloomFilter, updates <span class="keyword">chan</span>&lt;- DataUsageInfo, wantCycle <span class="type">uint32</span>, scanMode madmin.HealScanMode) <span class="type">error</span></span><br><span class="line">BackendInfo() madmin.BackendInfo</span><br><span class="line">StorageInfo(ctx context.Context) (StorageInfo, []<span class="type">error</span>)</span><br><span class="line">LocalStorageInfo(ctx context.Context) (StorageInfo, []<span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Bucket operations.</span></span><br><span class="line">MakeBucketWithLocation(ctx context.Context, bucket <span class="type">string</span>, opts BucketOptions) <span class="type">error</span></span><br><span class="line">GetBucketInfo(ctx context.Context, bucket <span class="type">string</span>) (bucketInfo BucketInfo, err <span class="type">error</span>)</span><br><span class="line">ListBuckets(ctx context.Context) (buckets []BucketInfo, err <span class="type">error</span>)</span><br><span class="line">DeleteBucket(ctx context.Context, bucket <span class="type">string</span>, opts DeleteBucketOptions) <span class="type">error</span></span><br><span class="line">ListObjects(ctx context.Context, bucket, prefix, marker, delimiter <span class="type">string</span>, maxKeys <span class="type">int</span>) (result ListObjectsInfo, err <span class="type">error</span>)</span><br><span class="line">ListObjectsV2(ctx context.Context, bucket, prefix, continuationToken, delimiter <span class="type">string</span>, maxKeys <span class="type">int</span>, fetchOwner <span class="type">bool</span>, startAfter <span class="type">string</span>) (result ListObjectsV2Info, err <span class="type">error</span>)</span><br><span class="line">ListObjectVersions(ctx context.Context, bucket, prefix, marker, versionMarker, delimiter <span class="type">string</span>, maxKeys <span class="type">int</span>) (result ListObjectVersionsInfo, err <span class="type">error</span>)</span><br><span class="line"><span class="comment">// Walk lists all objects including versions, delete markers.</span></span><br><span class="line">Walk(ctx context.Context, bucket, prefix <span class="type">string</span>, results <span class="keyword">chan</span>&lt;- ObjectInfo, opts ObjectOptions) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// function MUST NOT return a non-nil ReadCloser.</span></span><br><span class="line">GetObjectNInfo(ctx context.Context, bucket, object <span class="type">string</span>, rs *HTTPRangeSpec, h http.Header, lockType LockType, opts ObjectOptions) (reader *GetObjectReader, err <span class="type">error</span>)</span><br><span class="line">GetObjectInfo(ctx context.Context, bucket, object <span class="type">string</span>, opts ObjectOptions) (objInfo ObjectInfo, err <span class="type">error</span>)</span><br><span class="line">PutObject(ctx context.Context, bucket, object <span class="type">string</span>, data *PutObjReader, opts ObjectOptions) (objInfo ObjectInfo, err <span class="type">error</span>)</span><br><span class="line">CopyObject(ctx context.Context, srcBucket, srcObject, destBucket, destObject <span class="type">string</span>, srcInfo ObjectInfo, srcOpts, dstOpts ObjectOptions) (objInfo ObjectInfo, err <span class="type">error</span>)</span><br><span class="line">DeleteObject(ctx context.Context, bucket, object <span class="type">string</span>, opts ObjectOptions) (ObjectInfo, <span class="type">error</span>)</span><br><span class="line">DeleteObjects(ctx context.Context, bucket <span class="type">string</span>, objects []ObjectToDelete, opts ObjectOptions) ([]DeletedObject, []<span class="type">error</span>)</span><br><span class="line">TransitionObject(ctx context.Context, bucket, object <span class="type">string</span>, opts ObjectOptions) <span class="type">error</span></span><br><span class="line">RestoreTransitionedObject(ctx context.Context, bucket, object <span class="type">string</span>, opts ObjectOptions) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Multipart operations.</span></span><br><span class="line">ListMultipartUploads(ctx context.Context, bucket, prefix, keyMarker, uploadIDMarker, delimiter <span class="type">string</span>, maxUploads <span class="type">int</span>) (result ListMultipartsInfo, err <span class="type">error</span>)</span><br><span class="line">NewMultipartUpload(ctx context.Context, bucket, object <span class="type">string</span>, opts ObjectOptions) (uploadID <span class="type">string</span>, err <span class="type">error</span>)</span><br><span class="line">CopyObjectPart(ctx context.Context, srcBucket, srcObject, destBucket, destObject <span class="type">string</span>, uploadID <span class="type">string</span>, partID <span class="type">int</span>,</span><br><span class="line">startOffset <span class="type">int64</span>, length <span class="type">int64</span>, srcInfo ObjectInfo, srcOpts, dstOpts ObjectOptions) (info PartInfo, err <span class="type">error</span>)</span><br><span class="line">PutObjectPart(ctx context.Context, bucket, object, uploadID <span class="type">string</span>, partID <span class="type">int</span>, data *PutObjReader, opts ObjectOptions) (info PartInfo, err <span class="type">error</span>)</span><br><span class="line">GetMultipartInfo(ctx context.Context, bucket, object, uploadID <span class="type">string</span>, opts ObjectOptions) (info MultipartInfo, err <span class="type">error</span>)</span><br><span class="line">ListObjectParts(ctx context.Context, bucket, object, uploadID <span class="type">string</span>, partNumberMarker <span class="type">int</span>, maxParts <span class="type">int</span>, opts ObjectOptions) (result ListPartsInfo, err <span class="type">error</span>)</span><br><span class="line">AbortMultipartUpload(ctx context.Context, bucket, object, uploadID <span class="type">string</span>, opts ObjectOptions) <span class="type">error</span></span><br><span class="line">CompleteMultipartUpload(ctx context.Context, bucket, object, uploadID <span class="type">string</span>, uploadedParts []CompletePart, opts ObjectOptions) (objInfo ObjectInfo, err <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Policy operations</span></span><br><span class="line">SetBucketPolicy(context.Context, <span class="type">string</span>, *policy.Policy) <span class="type">error</span></span><br><span class="line">GetBucketPolicy(context.Context, <span class="type">string</span>) (*policy.Policy, <span class="type">error</span>)</span><br><span class="line">DeleteBucketPolicy(context.Context, <span class="type">string</span>) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Supported operations check</span></span><br><span class="line">IsNotificationSupported() <span class="type">bool</span></span><br><span class="line">IsListenSupported() <span class="type">bool</span></span><br><span class="line">IsEncryptionSupported() <span class="type">bool</span></span><br><span class="line">IsTaggingSupported() <span class="type">bool</span></span><br><span class="line">IsCompressionSupported() <span class="type">bool</span></span><br><span class="line">SetDriveCounts() []<span class="type">int</span> <span class="comment">// list of erasure stripe size for each pool in order.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Healing operations.</span></span><br><span class="line">HealFormat(ctx context.Context, dryRun <span class="type">bool</span>) (madmin.HealResultItem, <span class="type">error</span>)</span><br><span class="line">HealBucket(ctx context.Context, bucket <span class="type">string</span>, opts madmin.HealOpts) (madmin.HealResultItem, <span class="type">error</span>)</span><br><span class="line">HealObject(ctx context.Context, bucket, object, versionID <span class="type">string</span>, opts madmin.HealOpts) (madmin.HealResultItem, <span class="type">error</span>)</span><br><span class="line">HealObjects(ctx context.Context, bucket, prefix <span class="type">string</span>, opts madmin.HealOpts, fn HealObjectFn) <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Backend related metrics</span></span><br><span class="line">GetMetrics(ctx context.Context) (*BackendMetrics, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Returns health of the backend</span></span><br><span class="line">Health(ctx context.Context, opts HealthOptions) HealthResult</span><br><span class="line">ReadHealth(ctx context.Context) <span class="type">bool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Metadata operations</span></span><br><span class="line">PutObjectMetadata(context.Context, <span class="type">string</span>, <span class="type">string</span>, ObjectOptions) (ObjectInfo, <span class="type">error</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// ObjectTagging operations</span></span><br><span class="line">PutObjectTags(context.Context, <span class="type">string</span>, <span class="type">string</span>, <span class="type">string</span>, ObjectOptions) (ObjectInfo, <span class="type">error</span>)</span><br><span class="line">GetObjectTags(context.Context, <span class="type">string</span>, <span class="type">string</span>, ObjectOptions) (*tags.Tags, <span class="type">error</span>)</span><br><span class="line">DeleteObjectTags(context.Context, <span class="type">string</span>, <span class="type">string</span>, ObjectOptions) (ObjectInfo, <span class="type">error</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h3><p>Nas gateway 非常之简单： </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NAS implements Gateway.</span></span><br><span class="line"><span class="keyword">type</span> NAS <span class="keyword">struct</span> &#123;</span><br><span class="line">path <span class="type">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是一个 path 参数，但在 <code>NewGatewayLayer()</code> 中实例化了一个<code>FSObjects</code>，其结构是这样的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSObjects - Implements fs object layer.</span></span><br><span class="line"><span class="keyword">type</span> FSObjects <span class="keyword">struct</span> &#123;</span><br><span class="line">GatewayUnsupported</span><br><span class="line"></span><br><span class="line"><span class="comment">// Path to be exported over S3 API.</span></span><br><span class="line">fsPath <span class="type">string</span></span><br><span class="line"><span class="comment">// meta json filename, varies by fs / cache backend.</span></span><br><span class="line">metaJSONFile <span class="type">string</span></span><br><span class="line"><span class="comment">// Unique value to be used for all</span></span><br><span class="line"><span class="comment">// temporary transactions.</span></span><br><span class="line">fsUUID <span class="type">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// This value shouldn&#x27;t be touched, once initialized.</span></span><br><span class="line">fsFormatRlk *lock.RLockedFile <span class="comment">// Is a read lock on `format.json`.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// FS rw pool.</span></span><br><span class="line">rwPool *fsIOPool</span><br><span class="line"></span><br><span class="line"><span class="comment">// ListObjects pool management.</span></span><br><span class="line">listPool *TreeWalkPool</span><br><span class="line"></span><br><span class="line">diskMount <span class="type">bool</span></span><br><span class="line"></span><br><span class="line">appendFileMap   <span class="keyword">map</span>[<span class="type">string</span>]*fsAppendFile</span><br><span class="line">appendFileMapMu sync.Mutex</span><br><span class="line"></span><br><span class="line"><span class="comment">// To manage the appendRoutine go-routines</span></span><br><span class="line">nsMutex *nsLockMap</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不难看出，Nas 实际上是其于 MinIO 内置 <code>FSObjects</code> 来实现的。 <code>FSObjects</code> 是一种其于文件系统的网关，即使用本地文件系统来作为存储基础，这和 Nas 是一致的。</p><p>再来看 s3 gateway，相对来说就复杂得多。 </p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> s3Objects <span class="keyword">struct</span> &#123;</span><br><span class="line">minio.GatewayUnsupported</span><br><span class="line">Client     *miniogo.Core</span><br><span class="line">HTTPClient *http.Client</span><br><span class="line">Metrics    *minio.BackendMetrics</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> s3Objects 通过 <code>NewGatewayLayer()</code> 实例化，参数是 s3 认证要素 Credentials，内部会实例化一个 <code>http.Transport</code>，后续所有操作都会使用该http 客户端访问 s3 api 完成相应的功能实现。</p><h3 id="启动过程分析"><a href="#启动过程分析" class="headerlink" title="启动过程分析"></a>启动过程分析</h3><h4 id="Gateway-启动过程"><a href="#Gateway-启动过程" class="headerlink" title="Gateway 启动过程"></a>Gateway 启动过程</h4><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h234nd8mp2j21w40u0djj.jpg"><br>MinIO Gateway 是一个相关独立的系统，从命令行启动，具体的过程如上图。</p><p><code>main.go</code> 文件的中引入了 <code>cmd/gateway/</code> 这个包，<code>gateway</code> 包在<code>init</code> 过程中又引入了 <code>nas-gateway.go</code> 和 <code>s3-gateway.go</code> 。</p><p>这个 2 个就是系统默认附带的 NAS  网关 和 S3 网关的具体实现，它们在初始化时分别调用了 <code>cmd/gateway-main.go</code> 了 <code>RegisterGatewayCommand()</code> 方法，将自身注册成为 <code>gateway</code> 的子命令。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minio.RegisterGatewayCommand(cli.Command&#123;</span><br><span class="line">Name:               minio.S3BackendGateway,</span><br><span class="line">Usage:              <span class="string">&quot;Amazon Simple Storage Service (S3)&quot;</span>,</span><br><span class="line">Action:             s3GatewayMain,</span><br><span class="line">CustomHelpTemplate: s3GatewayTemplate,</span><br><span class="line">HideHelpCommand:    <span class="literal">true</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p>所有网关初始化完成后，<code>main()</code> 函数执行。过程中调用 <code>cmd/main.go</code> 中 <code>Main()</code> ，同时会通过 <code>NewApp</code> 创建一个 app 实例，最后运行 app 实例的  run 方法执行命令功能。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewApp</span><span class="params">()</span></span> *App &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;App&#123;</span><br><span class="line">Name:         filepath.Base(os.Args[<span class="number">0</span>]),</span><br><span class="line">HelpName:     filepath.Base(os.Args[<span class="number">0</span>]),</span><br><span class="line">Usage:        <span class="string">&quot;A new cli application&quot;</span>,</span><br><span class="line">UsageText:    <span class="string">&quot;&quot;</span>,</span><br><span class="line">Version:      <span class="string">&quot;0.0.0&quot;</span>,</span><br><span class="line">BashComplete: DefaultAppComplete,</span><br><span class="line">Action:       helpCommand.Action,</span><br><span class="line">Compiled:     compileTime(),</span><br><span class="line">Writer:       os.Stdout,&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>App 实例的初始化工作中包括 <code>gateway</code> 命令的注册。由于前面在 <code>init()</code>过程中已经将 <code>nas / s3</code> 的网关注册成为 <code>gateway</code> 的 <code>subCommands</code> ，因此 gateway 注册之后便 可以通过 <code>gateway s3</code> 子命令来启动 s3 网关。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">RegisterGatewayCommand</span><span class="params">(cmd cli.Command)</span></span> <span class="type">error</span> &#123;</span><br><span class="line">cmd.Flags = <span class="built_in">append</span>(<span class="built_in">append</span>(cmd.Flags, ServerFlags...), GlobalFlags...)</span><br><span class="line">gatewayCmd.Subcommands = <span class="built_in">append</span>(gatewayCmd.Subcommands, cmd)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在完成所有命令注册之后，会根据输入参数调用对应的 Gateway 子命，基中调用 <code>StartGateway()</code> 完成整个 Gateway 启动。</p><h4 id="S3-Gateway-启动"><a href="#S3-Gateway-启动" class="headerlink" title="S3 Gateway 启动"></a>S3 Gateway 启动</h4><p>在注册 s3 Gateway 子命令到 Gateway 时需要传递一个 Action，即 子命令的入口程序。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minio.RegisterGatewayCommand(cli.Command&#123;</span><br><span class="line">Name:               minio.S3BackendGateway,</span><br><span class="line">Usage:              <span class="string">&quot;Amazon Simple Storage Service (S3)&quot;</span>,</span><br><span class="line">Action:             s3GatewayMain,</span><br><span class="line">CustomHelpTemplate: s3GatewayTemplate,</span><br><span class="line">HideHelpCommand:    <span class="literal">true</span>,</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><p><code>s3GatewayMain()</code> 接受 Context 作接参数，在验证参数合法之后便会调用 <code>StartGateway()</code> 启动网关。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StartGateway - handler for &#x27;minio gateway &lt;name&gt;&#x27;.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">StartGateway</span><span class="params">(ctx *cli.Context, gw Gateway)</span></span> &#123;</span><br><span class="line"><span class="comment">// ... more code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于<code>StartGateway</code> 程序比较复杂，在这里就不贴代码，仅详细分析一下启动过程中所进行的主要操作。</p><ul><li>Gateway 在启动之后是一个常驻进程，因此首先需要为其注册系统信号监听</li><li>初始化终端日志</li><li>初始化 Gateway 级别的全局 Locker</li><li>初始化系统配置，MinIO 使用的是自己实的配置解析系统。</li><li>在完成基础设置之后会初使化 Gateway router， 用以给客户端暴露一组接口</li><li>初使化管理功能路由（admin router ）</li><li>初使化健康检查功能路由（healthy check router ）</li><li>初使化 Metric router</li><li>使用 Credentials 调用 NewGatewayLayer 获对 ObjectLayer 实例</li><li>启动 IAM 子程序 （IAM sub-system）</li><li>启动 httpServer 监听客户端请求</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面从代码级别梳理了 Gateway 的设计，在了解 Gateway 原理和启动过程之后，我们为基添加默认没有支持的存储产品也就变得非常简单。</p><p>参考：</p><ul><li><a href="https://www.flysnow.org/2020/10/19/minio-gateway-sourcecode.html">从源代码级别看懂MinIO对象存储网关的实现</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;业务系统因文件存储需求，需新增通用文件服务，除公有云上使用，还要满足私用化场景，几番对比之最终选择基于 MinIO 构建，一来在公有上将其用作存储网关，在私有化环境中直接用作对象存储服务。&lt;/p&gt;
&lt;p&gt;MinIO 是一个基于Apache License v2.0开源协议的</summary>
      
    
    
    
    
    <category term="存储" scheme="https://www.wewx.cn/tags/%E5%AD%98%E5%82%A8/"/>
    
    <category term="MinIO" scheme="https://www.wewx.cn/tags/MinIO/"/>
    
  </entry>
  
  <entry>
    <title>取货自动结算无人售货机实现方案</title>
    <link href="https://www.wewx.cn/2022/05/03/rfid.html"/>
    <id>https://www.wewx.cn/2022/05/03/rfid.html</id>
    <published>2022-05-03T17:30:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>前天出门想要买水，刚好发现有无人自动售货机。是那种先取后付的机器，即扫码或刷脸开门、自助取货、关门后自动结算与扣款。买完东西后，走在路上想了想这种售货机的几种实现方案：</p><p><strong>摄像头识别与对比</strong><br>在每层置物架上面，安装超广角摄像头，在开门前对柜内每层架子上的商品拍照，关门再度拍照，通过对比差异推断顾客买的是哪种商品。</p><p>目前各个场商的图像实别算法都非常强大，该方案实现起来比较简单且成本较低，目前市场上大部分的先取后付无人售货机都是基于这种方案来实现。</p><p>但这个方案似乎衣有不足：假设有可乐和雪碧2种商品，都是300ml，但售价不一样，如果2种商品混合了，顶上的摄像头只能看到罐顶，其实是不能准确区分是可乐还是雪碧的。</p><p><strong>重量感应</strong></p><!-- 这个方案是来自一个小朋友的的想法。这个方案是否能实现精准推断顾客取出的商器呢? --><p>先来设想一下：<br>每层置物架上一般会分成多列放置不同的商品，每一列的底部分安装重量感应器，在开门前记录各列的重量数据，在关门重新计算，通过各列的数据比对推断取出的商品。这么看似乎可行。</p><p>但对于上面的混合了商品的场景，一样无法应对。</p><p><strong>红外线取出商品条码</strong><br>在售货机内部，在各个角度部属红外条码读码器，尝试360度读取取出商品的条码。</p><p>但也有一些问题：</p><ul><li>若条码刚好被遮挡，可能就不太好读码</li><li>只能识别拿动的端品条码，但无法区分动作的含义，比如：是拿出不是放入</li><li>成本可能会比较高吧</li></ul><p><strong>商品包装上放置芯片</strong><br>当时只是一种设想，即类似物联网的一物一码，在每个商品上都放一个小芯片来通信。</p><p>后面详细了解了一下，还真有这种成熟的解决方案，叫做 射频识别（Radio Frequency IDentification，RFID），应用领域非常广泛。</p><p>在优衣库等卖场自助收银台，顾客把衣服放到扫瞄框中，收银系统就能自动实别所要购买的商品，就是 rfid 的一种实际应用，据说 rfid iot 低频芯片成本可以做成几分钱。除了在收银台，还能用于库存盘点、一物一码、链路追踪等各个应用场景。</p><p>以上只是当时的一些小小想法，随着物联网和大数据时代的到来、人工智能的兴起，智能设备已环绕在我们衣食住行的各个方面，还真有些期待未来的智能社会能够早些到来。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;前天出门想要买水，刚好发现有无人自动售货机。是那种先取后付的机器，即扫码或刷脸开门、自助取货、关门后自动结算与扣款。买完东西后，走在路上想了想这种售货机的几种实现方案：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摄像头识别与对比&lt;/strong&gt;&lt;br&gt;在每层置物架上面，安装超广角摄像</summary>
      
    
    
    
    
    <category term="随见随想" scheme="https://www.wewx.cn/tags/%E9%9A%8F%E8%A7%81%E9%9A%8F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>原来是这样的 PKCS</title>
    <link href="https://www.wewx.cn/2022/05/01/pkcs.html"/>
    <id>https://www.wewx.cn/2022/05/01/pkcs.html</id>
    <published>2022-05-01T07:30:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>敏感数据加密在聚合支付系统中是硬性的要求，因此在系统中 RSA 加密无处不在。这几天在为系统开发 Java  SDK，由于是初学 Java，过程中的密钥转换、加解密、签名等颇有一番折腾。现在 SDK 开发已结整，今天抽点时间把与 RSA 相关的各种知识梳理一下。</p><h2 id="PKI"><a href="#PKI" class="headerlink" title="PKI"></a>PKI</h2><p>公开密钥基础建设 (Public key infrastructure)，又称公开密钥基础架构、公钥基础建设、公钥基础设施、公开密码匙基础建设或公钥基础架构，是一组由硬件、软件、参与者、管理政策与流程组成的基础架构，其目的在于创造、管理、分配、使用、存储以及撤销数字证书。 密码学上，公开密钥基础建设借着数字证书认证机构将用户的个人身份跟公开密钥链接在一起。</p><p>简单来说，它是在1976年提出的一套密码学理论，后来以 PIK为基础设计出了一系列的公开密钥算法，常用的 RSA、DSA等等。这些算也被称为非对称机密算法，一对密钥由公钥和私钥组成，公钥可以由私钥导出，但私钥不能由由公钥反向推导计算。在实际的使用中，私钥自己持有，公钥可以明文发式发送给别人，从而解决了密钥交换的问题。</p><p>除了密码学算法，从PKI基础上也发展出了一些安全协议，像互联网上广泛应用的 SSL 协议、SET协议等。</p><p>SSL 协议利用 PKI 技术来进行身份验证、完成数据加密算法及密钥交换，很好地解决了身份验证、加密传输和密钥分发等问题。</p><p>SET （Secure Electronic Transaction）安全电子交协议，主要采用公钥密码体系和X.509数字证书标准，用于保障网上购物信息的安全性。SET 协议是 PKI 框架下的一个典型实现，同时也在不断升级和完善，如 SET 2.0 将支持借记卡电子交易，在金融领域有着广泛的应用。</p><h2 id="XKMS"><a href="#XKMS" class="headerlink" title="XKMS"></a>XKMS</h2><p>由微软、VerSign和webMethods三家公司共同发布，全称是 XML 密钥管理规范，也被称为第二代PKI标准。<br>它由两部分组成：</p><ul><li>XML密钥信息服务规范</li><li>XML 密钥注册服务规范</li></ul><p>XKMS 目前已是W3C 推荐使用的标准，微软已在 ASP.net 中集成， VerSign也已发布了基于 Java 的信任服务集成开发工具包。</p><h2 id="CA中心"><a href="#CA中心" class="headerlink" title="CA中心"></a>CA中心</h2><p>数字证书认证机构（Certificate Authority，缩写为CA），也称为电子商务认证中心、电子商务认证授权机构，是负责发放和管理数字证书的权威机构，并作为电子商务交易中受信任的第三方，承担公钥体系中公钥的合法性检验的责任。</p><p>CA中心为每个使用公开密钥的用户发放一个数字证书，数字证书的作用是证明证书中列出的用户合法拥有证书中列出的公开密钥。CA机构的数字签名使得攻击者不能伪造和篡改证书。它负责产生、分配并管理所有参与网上交易的个体所需的数字证书，因此是安全电子交易的核心环节。在SET交易中，CA不仅对持卡人、商户发放证书，还要对获款的银行、网关发放证书。</p><p>CA是证书的签发机构，它是公钥基础设施的核心。CA是负责签发证书、认证证书、管理已颁发证书的机关。它要制定政策和具体步骤来验证、识别用户身份，并对用户证书进行签名，以确保证书持有者的身份和公钥的拥有权。</p><p>CA也拥有用户的证书（内含公钥）和私钥。网上的公众用户通过验证CA的签名从而信任CA，任何人都可以得到CA的证书（含公钥），用以验证CA所签发的证书。</p><p>用户若欲获取证书，应先向CA提出申请，CA判明申请者的身份后，为之分配一个公钥，并将该公钥与其身份信息绑定，为该整体签名，签名后的整体即为证书，发还给申请者。</p><p>如果一个用户想鉴别另一个证书的真伪，他就用CA的公钥对那个证书上的签字进行验证，一旦验证通过，该证书就被认为是有效的。</p><p>为保证用户之间在网上传递信息的安全性、真实性、可靠性、完整性和不可抵赖性，不仅需要对用户的身份真实性进行验证，也需要有一个具有权威性、公正性、唯一性的机构，负责向电子商务的各个主体颁发并管理符合国际安全电子交易协议标准的电子商务安全证，并负责管理所有参与网上交易的个体所需的数字证书，因此CA是安全电子交易的核心环节。</p><p>在CA中心，普遍采的规范的是X.509和PKCS系列。</p><h2 id="X-509"><a href="#X-509" class="headerlink" title="X.509"></a>X.509</h2><p>X.509 是ITU-T标准化部门基于他们之前的ASN.1定义的一套公钥证书的格式标准。X.509证书里含有公钥、身份信息（比如网络主机名，组织的名称或个体名称等）和签名信息（可以是证书签发机构CA的签名，也可以是自签名）。</p><p>在X.509里，组织机构通过发起证书签名请求（CSR）来得到一份签名的证书。首先需要生成一对密钥对，然后用其中的私钥对CSR进行数字签署（签名），并安全地保存私钥。CSR进而包含有请求发起者的身份信息、用来对此请求进行验真的的公钥以及所请求证书专有名称。CSR里还可能带有CA要求的其它有关身份证明的信息。然后CA对这个CSR进行签名。 组织机构可以把受信的根证书分发给所有的成员，这样就可以使用公司的PKI系统了。浏览器（如Firefox）或操作系统预装有可信任的根证书列表，所以主流CA发布的TLS证书都直接可以正常使用。浏览器的开发者直接影响着它的用户对CA的信任。</p><h2 id="PKCS"><a href="#PKCS" class="headerlink" title="PKCS"></a>PKCS</h2><p>公钥加密标准（Public Key Cryptography Standards, PKCS），此一标准的设计与发布皆由RSA信息安全公司所制定。</p><p>PKCS 是一个系列集合，包含有15个标准。其中较常用的为 PKCS1、PKCS8、PKCS12</p><ul><li>PKCS1  RSA密码编译标准，定义了RSA的数理基础、公&#x2F;私钥格式，以及加&#x2F;解密、签&#x2F;验章的流程。</li><li>PKCS8 私钥消息表示标准，专门用来存储私钥的文件格式规范。</li><li>PKCS12 个人消息交换标准，定义了包含私钥与公钥证书（public key certificate）的文件格式。私钥采密码(password)保护。常见的PFX就履行了PKCS#12。</li></ul><h2 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h2><p>RSA算法由 RSA公司发布，属于 PKCS系列的加密算法。同时它是我们在日常开发中用得最多的密码学算法。<br>从上面不难看出，RSA密码学的密钥对应着2个标准: PKCS1 和  PKCS8。这2个标准在定义上存在一些重合又不完全互通，但是可以利用工具在2种标准之间对密钥格式进行转换。</p><p><strong>PKCS1私钥转换为PKCS8</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs8 -topk8 -inform PEM -<span class="keyword">in</span> private.pem -outform pem -nocrypt -out pkcs8.pem</span><br></pre></td></tr></table></figure><p><strong>PKCS8格式私钥再转换为PKCS1格式</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -<span class="keyword">in</span> pkcs8.pem -out pkcs1.pem</span><br></pre></td></tr></table></figure><p><strong>从PKCS1私钥中生成PKCS8公钥</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -<span class="keyword">in</span> private.pem -pubout -out public.pem</span><br></pre></td></tr></table></figure><p><strong>从PKCS8私钥中生成PKCS8公钥</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -<span class="keyword">in</span> pkcs8.pem -pubout -out public_pkcs8.pem</span><br></pre></td></tr></table></figure><p><strong>PKCS8公钥转PKCS1公钥</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -pubin -<span class="keyword">in</span> public_pkcs8.pem -RSAPublicKey_out</span><br></pre></td></tr></table></figure><p><strong>PKCS1公钥转换为PKCS8公钥</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl rsa -RSAPublicKey_in -<span class="keyword">in</span> pub_pkcs1.pem -pubout</span><br></pre></td></tr></table></figure><p><strong>小技巧</strong></p><ul><li><p>快速区分密钥</p><ul><li>PKCS8公钥格式  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-----BEGIN PUBLIC KEY-----</span><br><span class="line">base64格式的公钥内容</span><br><span class="line">-----END PUBLIC KEY-----</span><br></pre></td></tr></table></figure></li><li>PKCS1 公钥格式  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-----BEGIN RSA PUBLIC KEY-----</span><br><span class="line"><span class="built_in">base64</span>格式的公钥内容</span><br><span class="line">-----END RSA PUBLIC KEY-----</span><br></pre></td></tr></table></figure></li><li>PKCS8 私钥格式  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-----BEGI PRIVATE KEY-----</span><br><span class="line"><span class="built_in">base64</span>格式的私钥内容</span><br><span class="line">-----END RSA PRIVATE KEY-----</span><br></pre></td></tr></table></figure></li><li>PKCS1 私钥格式  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-----BEGIN PRIVATE KEY-----</span><br><span class="line"><span class="built_in">base64</span>格式的私钥内容</span><br><span class="line">-----END RSA PRIVATE KEY-----</span><br></pre></td></tr></table></figure></li></ul></li><li><p>在 Java 体系中，常用 PKCS8 格式的密钥</p></li><li><p>在其他编成语言中，一般常用 PKCS1 格式的密钥</p></li></ul><p>上一张体系图：</p><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1sxyo443mj21bz0u0wi3.jpg" alt="吹雨听风原创的PKI知体系图"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;敏感数据加密在聚合支付系统中是硬性的要求，因此在系统中 RSA 加密无处不在。这几天在为系统开发 Java  SDK，由于是初学 Java，过程中的密钥转换、加解密、签名等颇有一番折腾。现在 SDK 开发已结整，今天抽点时间把与 RSA 相关的各种知识梳理一下。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
    <category term="PKCS" scheme="https://www.wewx.cn/tags/PKCS/"/>
    
    <category term="PKI" scheme="https://www.wewx.cn/tags/PKI/"/>
    
    <category term="RSA" scheme="https://www.wewx.cn/tags/RSA/"/>
    
  </entry>
  
  <entry>
    <title>这回是个 Java 小白</title>
    <link href="https://www.wewx.cn/2022/04/28/first-lesson-of-java.html"/>
    <id>https://www.wewx.cn/2022/04/28/first-lesson-of-java.html</id>
    <published>2022-04-28T16:40:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>Java 是个有20多年历史的编程语言，语言的生态和应用场景极其完善。尤其是在企业环境中有着非常官方的应用。</p><p>此前一直没有使用过 Java，对 java 并不是很，而现在马上需要给客户交付 Java 语言的支付 SDK，临时来报佛脚，边看边学边写SDK，过程着顺便做一些记录。</p><h2 id="名词"><a href="#名词" class="headerlink" title="名词"></a>名词</h2><p>不过对于新手来说，首选面对的就是能排一长排的以 Java 为开头命名的名语，让人很是困惑：</p><ul><li><code>Java EE</code> Enterprise Edition。这个版本以前称为 J2EE。企业版本帮助开发和部署可移植、健壮、可伸缩且安全的服务器端 Java 应用程序。Java EE 是在 Java SE 的基础上构建的，它提供 Web 服务、组件模型、管理和通信 API，可以用来实现企业级的面向服务体系结构（service-oriented architecture，SOA）和 Web 2.0 应用程序。</li><li><code>Java SE</code> Standard Edition。它允许开发和部署在桌面、服务器、嵌入式环境和实时环境中使用的 Java 应用程序。Java SE 包含了支持 Java Web 服务开发的类，并为 Java Platform，Enterprise Edition（Java EE）提供基础。</li><li><code>Java ME</code> Micro Edition。Java ME 为在移动设备和嵌入式设备（比如手机、PDA、电视机顶盒和打印机）上运行的应用程序提供一个健壮且灵活的环境。Java ME 包括灵活的用户界面、健壮的安全模型、许多内置的网络协议以及对可以动态下载的连网和离线应用程序的丰富支持。基于 Java ME 规范的应用程序只需编写一次，就可以用于许多设备，而且可以利用每个设备的本机功能。</li><li><code>jre</code> 是Java的运行环境。面向Java程序的使用者，而不是开发者 。如果你仅下载并安装了JRE，那么你的系统只能运行Java程序。JRE是运行Java程序所必须环境的集合，包含JVM标准实现及Java核心类库。它包括Java虚拟机、Java平台核心类和支持文件。 它不包含开发工具(编译器、调试器等)。</li><li><code>jdk</code> JDK(Java Development Kit)又称J2SDK(Java2 Software Development Kit)，是Java开发工具包， 它提供了Java的开发环境(提供了编译器javac等工具，用于将java文件编译为class文件)和运行环境(提供了JVM和Runtime辅助包，用于解析class文件使其得到运行)。如果你下载并安装了JDK，那么你不仅可以开发Java程序，也同时拥有了运行Java程序的平台。 JDK是整个Java的核心，包括了Java运行环境(JRE)，一堆Java工具tools.jar和Java标准类库 (rt.jar)。</li></ul><p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1r10a12o9j20fk0b2t9r.jpg" alt="jre与jdk对比图"></p><p>除了上面的，还有一堆的令人困惑版本号：Java 1.x Java 1x。</p><blockquote><p>首先1996年发布了最初版本Java1.0，此后为Java1.1、J2SE1.2、J2SE1.3、J2SE1.4、采用 1.X的命名方式，直到 2004 年的 JavaOne 会议后版本数提升为 5.0，这一新版本为Java SE5.0，在 2006 年 Sun 公司终结了已经有 8 年历史的 J2SE、J2EE、J2ME 的命名方式启用了今天的 Java SE、Java EE、Java ME  命名方式，而此后的版本为 Java SE6、Java SE7、Java SE8、Java SE9、Java SE10、Java SE11、Java SE12、JAVA SE18</p></blockquote><blockquote><p>而JDK则在 Java1.0 到 Java9 对应每一个版本号 ：JDK1.0、JDK1.2 … JDK1.8、JDK1.9，Java10 以后JDK对应名称为：JDk10、JDK11、JDK12、JDK18</p></blockquote><p>所以</p><ul><li><code>Java 8</code> 指 Java SE 8.0 的版本</li><li><code>Java 18</code> 指 Java SE 18 的版本 </li><li><code>JDK 1.8</code> 则指 Java 8 对应的 JDK 版本</li></ul><h2 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h2><p>Java现在的最新版本是 Java 18，但在市场上最受欢迎的以及最为普遍的不是  <code>Java 8</code>，这又带来了环境与版本的问题。</p><p>但好在安装 Java 之后提供一个工具来管理当前系统上的java版本。命令是 <code>/usr/libexec/java_home</code> 。</p><p>在终端运行 <code>/usr/libexec/java_home -V</code> 可以看到系统中安装的所有版本的 Java  程序，并可以切换到对应的版本： <code>/usr/libexec/java_home -v &lt;version&gt;</code></p><p>如：<code>/usr/libexec/java_home -v 1.8</code>，可以切换到 JDK 1.8。之后可通过 <code>java -version</code> 来查看当前的版本。</p><h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><p>在 java 中有几个重要的环境变量需要在安装完 Java 之后进行配置：</p><ul><li><code>JAVA_HOME</code> 通常它指的是JDK的目录。如果需要JDK的话，大部分程序会默认去环境变量中取JAVA_HOME这个变量。</li><li><code>JRE_HOME</code> 同样，这也是一个约定的变量，通常指JRE目录。其实大部分Java程序不需要JDK，而是只需要其子集JRE，所以很多程序也会去取这个变量来用。</li></ul><p>在程序中，也可以通过 Java 提供的 API 来获取：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find <span class="type">String</span> <span class="variable">env</span> <span class="operator">=</span> System.getenv(<span class="string">&quot;PATH&quot;</span>);</span><br><span class="line">System.out.println(env);</span><br></pre></td></tr></table></figure><p>因此，我们可以将设置版本以及选设置环境变量放在 <code>~/.bash_profile</code> 或 <code>~/.zshrc</code> 文件中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/libexec/java_home -v 1.8.0_331</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;JAVA_HOME&#125;</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><h2 id="后缀"><a href="#后缀" class="headerlink" title="后缀"></a>后缀</h2><p>在 Java 程序中，有几种不同类型的文件后缀名，对应到程序的源码、编译等不同的阶段。</p><ul><li><code>.java</code> 是 Java 程序的源代码</li><li><code>.class</code> 是 .java 源代码编译的的字节码文件，真正可以被 jvm 执行</li><li><code>.jar</code> 将一组 .class 文件打包而来，本质是一个 zip 格式的压缩文件</li></ul><h2 id="Maven"><a href="#Maven" class="headerlink" title="Maven"></a>Maven</h2><p>Apache Maven，是一个软件（特别是Java软件）项目管理及自动构建工具，由Apache软件基金会所提供。</p><p>Maven项目使用项目对象模型（Project Object Model，POM）来配置。</p><p>项目对象模型存储在名为 pom.xml 的文件中。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Java 是个有20多年历史的编程语言，语言的生态和应用场景极其完善。尤其是在企业环境中有着非常官方的应用。&lt;/p&gt;
&lt;p&gt;此前一直没有使用过 Java，对 java 并不是很，而现在马上需要给客户交付 Java 语言的支付 SDK，临时来报佛脚，边看边学边写SDK，过程着</summary>
      
    
    
    
    
    <category term="Java" scheme="https://www.wewx.cn/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>从扫码枪说明书看创业</title>
    <link href="https://www.wewx.cn/2022/04/24/thoughts-from-the-barcode-scanner-manual.html"/>
    <id>https://www.wewx.cn/2022/04/24/thoughts-from-the-barcode-scanner-manual.html</id>
    <published>2022-04-24T15:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>聚合支付系统第一个版本上线有些日子，第一个版本主打是线上支付，所有对于扫码的支付方式一直没有支持。</p><p>最近在对接某一开源商城系统，其中一个功能便是要支持线下支付，故而买了一个扫码枪用来测试扫码功能。</p><p>购买的时考虑到只是测试使用，直接买了最为便宜的一款，价格不到50元。产品收到，拆开包装盒，接上电脑便开始使用。第二日收拾盒子时发现里面有一本厚厚的书明书。当时我的第一感觉是这扫码枪全新只有一个按钮，对接条码按下按钮就能读取，这么简单的一个产品为啥需要这么厚的说明书，莫非还要设置不成，这本说明书里都讲些啥？</p><p>好奇之下翻了翻。翻开说明书才发现是我肤浅了！没错就是这么个拿手上按一下按钮就能用的小设备，说明书上大概有20种不同的配置！涵盖识读模式、延迟、出厂设置、结束符设置、扫描模式等等。不仅这么多配置的数量没想到，而且配置的方式也是之前没有想到的：厂家也把个配置项做成了条码，扫码产品本身扫一下就能完成设置。</p><p>设置是这么的简单，使用产品本身最大也是唯一的功能扫一扫，就能轻轻松松的实现自定义设置，不可谓不是大道至简。</p><p>相信扫码枪厂家也知道，这个产品大部分的买家都知道如何使用，甚至都不会看说明书，即使专业用户需要更改默认设置的也不多，即便如此，他们还是把产品做得很有深度。</p><p>同样，做为一个创业者，我们产品在满足大部分的常境规用户，还需要学习这种精益求精的精神，潜心打磨，在细节处，在后台，也要认真的去设计和对待，以满足普通用户之外的专业用户需要，从而赢得口碑。</p><p>我所理解的”极致”，就是在自己创业的领域，做到比绝大多数同行优秀一点，专注努力，步步为营，稳扎稳打。</p><p>突发的感慨，致自已，致伙伴，加油！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;聚合支付系统第一个版本上线有些日子，第一个版本主打是线上支付，所有对于扫码的支付方式一直没有支持。&lt;/p&gt;
&lt;p&gt;最近在对接某一开源商城系统，其中一个功能便是要支持线下支付，故而买了一个扫码枪用来测试扫码功能。&lt;/p&gt;
&lt;p&gt;购买的时考虑到只是测试使用，直接买了最为便宜的一</summary>
      
    
    
    
    
    <category term="创业" scheme="https://www.wewx.cn/tags/%E5%88%9B%E4%B8%9A/"/>
    
    <category term="感想" scheme="https://www.wewx.cn/tags/%E6%84%9F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>给博客上了一款新主题 《snow white》</title>
    <link href="https://www.wewx.cn/2022/04/16/hexo-theme-snow-white.html"/>
    <id>https://www.wewx.cn/2022/04/16/hexo-theme-snow-white.html</id>
    <published>2022-04-16T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>使用 hexo 创建博客也有好几个年头了，可已写下的文章的不多，就一直是默认的主题挂在那儿。</p><p>今年以来立志要练习写作，也就打算好好的整一下这个静态博客，第一件事自然是得整个好看的、符合我极简审美的主题。耐何在 Hexo 主题站上找了一圈，也没有找到完全合意的主题，那就自己写一个。说干就开，于是之款起名叫《snow white》的主题诞生。</p><p>这是我开发的第一款主题，虽有些不足，但也有些特点。</p><h3 id="极致的简约"><a href="#极致的简约" class="headerlink" title="极致的简约"></a>极致的简约</h3><p>整体以白色设计为主，没有边边框框、背景色之类的装饰，自然更不会有 icon 和各种图标了。</p><h3 id="使用-Tailwind-css"><a href="#使用-Tailwind-css" class="headerlink" title="使用 Tailwind css"></a>使用 Tailwind css</h3><p>主题的风格样式完全使用 <a href="https://tailwindcss.com/">Tailwind css</a> 进行定义，编译后也仅仅只有 13kb。Tailwind css　是一个功能类优先的 CSS 框架，样式能够语义化，这样整体的布局、样式都更加清晰明了，方便进行二次开发和调整。</p><h3 id="中文排版"><a href="#中文排版" class="headerlink" title="中文排版"></a>中文排版</h3><p>中文排版一直是个比较头痛的问题了，为使文章易于阅读，在本主题中直接使用 <a href="https://typo.sofi.sh/">typo css</a> 进行文章正文的排版。　</p><h3 id="文章优化"><a href="#文章优化" class="headerlink" title="文章优化"></a>文章优化</h3><p>扩展了文章元数据，增加了</p><ul><li>相关文章</li><li>外部链接，可以申明本文的转载来源</li></ul><h3 id="seo-优化"><a href="#seo-优化" class="headerlink" title="seo 优化"></a>seo 优化</h3><p>扩展了页面和文章的 seo 元数据，支持为每篇文章或每个页面设置 seo 信息</p><ul><li>seo 描述　</li><li>seo 关键词　</li><li>seo title</li></ul><h3 id="深色模式"><a href="#深色模式" class="headerlink" title="深色模式"></a>深色模式</h3><p>暂未之前，后续再说。</p><h2 id="主题下载"><a href="#主题下载" class="headerlink" title="主题下载"></a>主题下载</h2><p>从 github 下载<a href="https://github.com/cmzz/hexo-theme-snow-white">《snow white》</a>主题</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>在制作主题的过程中，参考了以下几款优秀主题：</p><ul><li><a href="https://d2fan.com/">https://d2fan.com/</a></li><li><a href="http://niexiaotao.cn/">http://niexiaotao.cn/</a></li><li><a href="https://typo.sofi.sh/">https://typo.sofi.sh/</a></li></ul>]]></content>
    
    
    <summary type="html">snow white 是 hexo 的一款极致简约的博客主题，纯白色调设计，无任何多余元素和图标，seo 支持友好，如果喜欢简约风格可以尝试</summary>
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>不同场景下的文件服务选型</title>
    <link href="https://www.wewx.cn/2022/02/23/file-service-selection.html"/>
    <id>https://www.wewx.cn/2022/02/23/file-service-selection.html</id>
    <published>2022-02-23T15:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>文件服务是一个非常基础的功能，一般来说，每个系统都会有类似上传头像、上传图片、上传办公文件等等类似的图片或文件上传功能。</p><p>每个项目的这部分功能其实是相似的，要说不同，也就是上传的文件类型不同，大小的限制不一样，访问的权限控制的力度不同，如果一个公司中有多个不同的项目，就非常有必要设计一个通用的文件服务来满足所有的类似的文件上传的功能。</p><p>在设计文件服务中，有以下几个关键属性需要我们考虑：</p><ul><li>文件内容的敏感程度</li><li>文件平均大小</li><li>文件的使用方式、使用频率</li><li>文件的访问控制</li><li>文件的重要程度</li></ul><p>上面列举的文件属性都是从文件本身和使用方面考虑的，属性的不同决定着必须采取不同的方式来对待：</p><h4 id="文件内容的敏感程度"><a href="#文件内容的敏感程度" class="headerlink" title="文件内容的敏感程度"></a>文件内容的敏感程度</h4><p>什么是内容的敏感程度？敏感数据主要包括个人隐私信息、密码&#x2F;密钥、敏感图片等高价值数据。用大白话来说就是上传的这个文件，在上传者匿名的情况下，文件的内容会不会暴露上传者或其他人&#x2F;事物&#x2F;公司的敏感信息。例如，在金融或支付之类的系统中，文件中包含银行卡号码、电话号码、用户身份证号码，或是企业的合同等等，包含这类信息的文件就可以说是敏感文件。反之像是用户随手发到博客的图片，即使被人无意中看到也没关系，这就不敏感。</p><p>在我们设计文件服务服务的时候，如果需要存储敏感文件，那么就要充分的考虑文件内容的保密性。可以采取的常见措施为：</p><p><strong>敏感数据识别</strong>：接接收到用户上传的数据时，能够有相应的算法实别到该文件属于较为敏感的数据，以便在存储时加以区别对待。</p><p><strong>分块存储</strong>：即将文件切为很多个块。放在不同的地方，即使得到一块也无法还原文件内容。</p><p><strong>加密存储</strong>：在文件写入到磁盘保存之前，对文件字节进行加密。如果当年冠希哥懂点安全的话，那观众就少了一个大瓜。</p><p><strong>混淆存储</strong>：保存文件的时候，用一定的规则将文件内容打乱重排，窃取或看到的人也就看不懂了，从而起到保护文件中机密的作用</p><p><strong>同城冗余存储</strong>：在同一个城市的多个分区数据中心对文件保存多份副本。当某个可用区不可用时，仍然能够保障数据的正常访问。</p><p><strong>跨区域复制</strong>：跨越多个不同的地域数据中心之间复制数据，让重要数据一次保存到多个城市，从而实现更高的可用性。</p><h4 id="文件平均大小"><a href="#文件平均大小" class="headerlink" title="文件平均大小"></a>文件平均大小</h4><p>文件的体积决定着文件的访问和存储的效率。那是不是小文件相对于大文件是不是在读取速度、保存的写入速度等各方面都要快呢？并不是的。 </p><p>在淘宝系统中，由于商品图片、装修图片、描述图片都属于小图片，系统中就存在海量的小文件，或是在机器学习中，同样的也会用到大量的小文件。对于这些海量的小文件，如果采用常规的存储和访问方式，效率将会极其低下。反过来，大量的大文件也存在相应的问题，于是在这样的背景下，就诞生了各种不同的文件存储系统来适配不同的场景，如：小文件适用的 TFS，大文件适用的 GridFS，还有 HDFS、FastDFS 等等，这里就不做展开了。整理了一些参考，如下。</p><p><strong>小文件存储</strong>：</p><ul><li><a href="https://blog.51cto.com/u_14977574/2547854">支撑 Bilibili 的小文件存储系统</a></li></ul><p><strong>大文件存储</strong>：</p><ul><li><a href="https://support.huaweicloud.com/topic/182577-1-D">大文件存储系统</a></li></ul><h4 id="使用方式和频率"><a href="#使用方式和频率" class="headerlink" title="使用方式和频率"></a>使用方式和频率</h4><p>保存的文件的访问方式和访问频率通常由使用场景决定，在实际中，我们需要根据工作的负载和访问模式来确定最佳的存储方案。</p><p><strong>归档存储</strong>：因其价格低廉、通常为离线冷数据存储，非常适合海量、非结构化数据长时间备份。<br><strong>低频访问</strong>：低频访问存储价于标准化的存储和归档存存之间，支持数据实时访问，适用于较低访问频率（平均每月访问频率1到2次）的业务场景。</p><h4 id="文件的访问控制"><a href="#文件的访问控制" class="headerlink" title="文件的访问控制"></a>文件的访问控制</h4><p>文件是否能公开访问？能否授权给其他人访问？组织内的其他人否访问？</p><p>通常情况下，在设计文件服务时，除了默认只有资源拥有者或者被授权的用户允许访问外，还应支持用户授权他人访问或使用自己的上传的文件资源，需要考虑权限控制策略以解决向他人授予特定权限的问题。</p><h4 id="重要程度"><a href="#重要程度" class="headerlink" title="重要程度"></a>重要程度</h4><p>在现在信息化社会中，数据和文件就是最为重要的资产，如果要保存重要的文件，意味着在存储和使用的过程中需要做好充分的防丢失、防止损坏的措施。应对丢失最常见的方式就是异地、多城、多云同步备份，保持多份文案拷贝，此外文件版本控制机制也能比较好的防止文件意外损坏。</p><p>最后，现在处于一个云时代，在实际的工作实践中，我们在做文件系统的设计选型时，通常会考虑在底层使用云存储，例如各平台的对象存储服务（OSS）。那么此时在价格因素之外，还要充分的评估云产品的特性能否匹配到我们系统的使用场景和要求，系统评估后再做决策。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;文件服务是一个非常基础的功能，一般来说，每个系统都会有类似上传头像、上传图片、上传办公文件等等类似的图片或文件上传功能。&lt;/p&gt;
&lt;p&gt;每个项目的这部分功能其实是相似的，要说不同，也就是上传的文件类型不同，大小的限制不一样，访问的权限控制的力度不同，如果一个公司中有多个不同</summary>
      
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="存储" scheme="https://www.wewx.cn/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Docker 网络模式不完全指南</title>
    <link href="https://www.wewx.cn/2018/10/10/docker-network-mode-not-complete-guide.html"/>
    <id>https://www.wewx.cn/2018/10/10/docker-network-mode-not-complete-guide.html</id>
    <published>2018-10-10T00:00:00.000Z</published>
    <updated>2023-06-01T15:13:37.686Z</updated>
    
    <content type="html"><![CDATA[<p>本次分享没有：</p><ul><li>Docker的背景</li><li>Docker的整体架构</li><li>Docker的核心实现技术</li><li>Docker的高级用法</li><li>Docker的使用秘笈</li></ul><p>本次分享是：<br><em>Docker使用中的…</em><br><em>一条命令的…</em><br><em>一个参数的..</em><br><em>不完全说明.</em></p><h3 id="Docker网络模式"><a href="#Docker网络模式" class="headerlink" title="Docker网络模式"></a>Docker网络模式</h3><p>一般文章中说的网络模式，其实主要是指 <code>docker run</code> 命令的 <code>--net</code> 或 <code>--network</code> 参数所支持的模式，默认包括：</p><ol><li>bridge模式（划重点，最后说）<br> 使用 <code>--network=bridge</code> 指定，默认设置可不指定</li><li>host模式<br> 使用 <code>--network=host</code> 指定</li><li>container模式<br> 使用 <code>--network=container:NAME_or_ID</code> 指定</li><li>none模式<br> 使用 <code>--network=none</code> 指定</li></ol><p>有时网络模式也会包括其他的模式，例如 <a href="https://docs.docker.com/network/macvlan/">macvlan</a>、<a href="https://docs.docker.com/network/overlay/">overlay</a> 等，这些并不仅通过上述参数指定，属于高级用法，如有需要可查阅文档。<br>这里只介绍常见的上述4种模式。</p><h4 id="host模式"><a href="#host模式" class="headerlink" title="host模式"></a>host模式</h4><p>容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。</p><ul><li>试验<br>创建容器：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -d --network host --name my_nginx nginx</span><br></pre></td></tr></table></figure>在宿主机检查端口监听情况：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -tulpn | grep :80</span><br></pre></td></tr></table></figure></li></ul><p>通过这种模式，一些命令行工具可以很方便地通过docker来使用，避免在宿主机安装大量的依赖包，也便于随时清理。例如启动一个 tcpdump 的容器抓取主机上的网络报文：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --net=host -v $PWD:/data corfr/tcpdump -i any -w /data/dump.pcap &quot;icmp&quot;</span><br></pre></td></tr></table></figure><h4 id="container模式"><a href="#container模式" class="headerlink" title="container模式"></a>container模式</h4><p>在了解了 host 模式后，这个模式也就好理解了。这个模式创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。<br>kubernetes 的 pod 可以认为就是用这个实现的（？），同一个 pod 中的容器共享一个 network namespace。</p><ul><li>试验<br>我们运行两个 nginx 容器：web1 和 web2：<br>web1 监听在 80 端口，使用默认的网络模型<br>web2 监听在 8080 端口，使用 container 网络模型共享 web1 的网络<br>先启动 web1，通过端口映射把端口绑定到主机上：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name=web1 -p 80:80 nginx</span><br></pre></td></tr></table></figure>使用 curl 命令验证容器运行正常：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:80</span><br></pre></td></tr></table></figure>第二个容器和 host 模式相同，使用 –net 参数让新建的容器使用 web1 的网络：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --name=web2 -v $&#123;PWD&#125;/default.conf:/etc/nginx/sites-available/default -v $&#123;PWD&#125;/index.html:/var/www/html/index.html -d --net=container:web1 nginx</span><br></pre></td></tr></table></figure>其中 <code>default.conf</code> 文件就是修改了 nginx 默认配置文件的端口，把它变成 8080；<code>inedx.html</code> 可以随便修改一点，以区别于默认的内容。<br>在 web1 或 web2 容器里面可以验证 nginx 服务：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:8080</span><br></pre></td></tr></table></figure>在两个容器中，可以分别通过 <code>ip addr</code> 查看网络配置，是完全一致的（命令和执行结果从略）。</li></ul><h4 id="none模式"><a href="#none模式" class="headerlink" title="none模式"></a>none模式</h4><p>这个模式和前两个不同。在这种模式下，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。<br>选择这种模式，一般是用户对网络有自己特殊的需求，不希望 docker 预设置太多的东西。</p><h4 id="bridge模式"><a href="#bridge模式" class="headerlink" title="bridge模式"></a>bridge模式</h4><p>在默认的bridge模式下，docker 会在宿主机上新创建一个网桥，可以把它想象成一个虚拟的交换机，所有的容器都是连到这台交换机上面的。docker 会从私有网络中选择一段地址来管理容器，比如 172.17.0.1&#x2F;16（这个地址根据你之前的网络情况而有所不同）。通过网桥，让容器的子网可以访问宿主机所连接的外网，并且可以通过 <strong>端口映射</strong> 来实现容器对外暴露端口提供服务（即外部可以通过宿主机、网桥访问容器上的服务）。这是最常用的网络模式，又分为以下两种情况：</p><ol><li>使用默认网络</li></ol><p>默认的网络docker将其称为 <code>bridge</code> 网络，在这种情况下，容器可以相互通信（若出于安全考虑，也可以禁止它们之间通信，方法是在 <code>DOCKER_OPTS</code> 变量中设置 <code>--icc=false</code>，这样只有使用 <code>--link</code> 选项才能使两个容器通信，关于 <code>--link</code> 后面还会说到）。<br>容器可以访问外部网络，但是Docker容器的IP、网络等对外是不可见的。即外部服务发现的访问客户端IP，是宿主机IP而不是容器IP。<br>而通过端口映射，可以让外部访问Docker容器的服务。</p><ul><li>试验<br>我们首先用下面命令创建一个含有 web 应用的容器，将容器的 80 端口映射到主机的 80 端口。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -d --name web -p 80:80 nginx</span><br></pre></td></tr></table></figure></li></ul><p>如果宿主机的IP为10.10.101.105，外界只需访问10.10.101.105:80 就可以访问到容器中的服务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v http://10.10.101.105:80</span><br></pre></td></tr></table></figure><p>查看默认的网络</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">$ docker network inspect bridge</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;aeeabedfaa07ae4d06d0dad4ede4126a93e0efd9a2a5f0034551665aa2744976&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2019-01-29T03:25:10.046595598Z&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: null,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;</span><br><span class="line">            &quot;1a30155cb661730fe5733a20ca8f692da0ce9edae1932b902399ed31e4b42cbd&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;web&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;2d2009eb67cd56b9a40bea4d43be87d45fd61994a85e27fd0546494d065cfd3b&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;</span><br><span class="line">            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,</span><br><span class="line">            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,</span><br><span class="line">            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><ol start="2"><li>自行创建网络</li></ol><p>这种情况与使用默认网络基本类似，只是通过命令创建自有的网络和网桥来实现通信，这样就可以自己规划网络拓扑。在建立开发环境时，这是很常用的一种方式。laradock 即采用这种方式。</p><ul><li>试验<br>创建一个名为 <code>web-net</code> 的自定义网络，使用bridge网络驱动：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create --driver bridge web-net</span><br></pre></td></tr></table></figure></li></ul><p>查看一下已经创建的网络列表，可以看到除了docker自行创建的 <code>bridge</code> 网络，还有刚创建的 <code>web-net</code> ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network ls</span><br></pre></td></tr></table></figure><p>查看 <code>web-net</code> 网络的详细信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ docker network inspect web-net</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;web-net&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;79be842fea854d32708498bb01bf67e3b4967ffe32405493be2f1c6424eb4752&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2019-01-29T06:57:23.58969899Z&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>创建两个容器，使用 <code>web-net</code> 网络：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -d --name web1 --network web-net nginx</span><br><span class="line">docker run --rm -d --name web2 --network web-net nginx</span><br></pre></td></tr></table></figure><p>再次查看 <code>web-net</code> 网络的详细信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">$ docker network inspect web-net</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;Name&quot;: &quot;web-net&quot;,</span><br><span class="line">        &quot;Id&quot;: &quot;79be842fea854d32708498bb01bf67e3b4967ffe32405493be2f1c6424eb4752&quot;,</span><br><span class="line">        &quot;Created&quot;: &quot;2019-01-29T06:57:23.58969899Z&quot;,</span><br><span class="line">        &quot;Scope&quot;: &quot;local&quot;,</span><br><span class="line">        &quot;Driver&quot;: &quot;bridge&quot;,</span><br><span class="line">        &quot;EnableIPv6&quot;: false,</span><br><span class="line">        &quot;IPAM&quot;: &#123;</span><br><span class="line">            &quot;Driver&quot;: &quot;default&quot;,</span><br><span class="line">            &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">            &quot;Config&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Internal&quot;: false,</span><br><span class="line">        &quot;Attachable&quot;: false,</span><br><span class="line">        &quot;Ingress&quot;: false,</span><br><span class="line">        &quot;ConfigFrom&quot;: &#123;</span><br><span class="line">            &quot;Network&quot;: &quot;&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;ConfigOnly&quot;: false,</span><br><span class="line">        &quot;Containers&quot;: &#123;</span><br><span class="line">            &quot;614b91e2000356945a1aba29cfa4dacad04f0bf254972c78a54aacd3663079ca&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;web1&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;d0254e60f67f6d5eb155731bb028c40a2b723b0ef2aacfbe641b96dd67ca5a75&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:02&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;172.18.0.2/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;6aa947097ca8b6189c7a057b545ff718a82b15df4212cad6ee1ce3f2031e4bb5&quot;: &#123;</span><br><span class="line">                &quot;Name&quot;: &quot;web2&quot;,</span><br><span class="line">                &quot;EndpointID&quot;: &quot;9be085bf7f3d075f4224b285d7a3c4c382b516c22698a151c1049ea9298ee567&quot;,</span><br><span class="line">                &quot;MacAddress&quot;: &quot;02:42:ac:12:00:03&quot;,</span><br><span class="line">                &quot;IPv4Address&quot;: &quot;172.18.0.3/16&quot;,</span><br><span class="line">                &quot;IPv6Address&quot;: &quot;&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Options&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Labels&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>可见容器 <code>web1</code> 和 <code>web2</code> 已经加入了此网络，并且分配了各自的网络IP，并使用同一个网络和网关。</p><h4 id="bridge模式下默认网络和自建网络的差别"><a href="#bridge模式下默认网络和自建网络的差别" class="headerlink" title="bridge模式下默认网络和自建网络的差别"></a>bridge模式下默认网络和自建网络的差别</h4><ol><li>提供更好的网络隔离和更灵活的拓扑</li></ol><p>这一点不言而喻，只是需了解：各容器的全部端口，对当前网络（不论是默认还是自建）内的其他容器完全开放，而对宿主机和外界都不开放，除非设置端口映射。</p><ol start="2"><li>自建网络自动提供了各容器名称的DNS解析</li></ol><p>默认网络下，各容器只能通过IP访问，除非显式设置 <a href="https://docs.docker.com/network/links/">–link 选项</a><br>而在自建网络中，默认就可以在某个容器中通过容器的名称来访问其他容器。</p><ol start="3"><li><p>容器可以动态的（无需重启容器）加入自建网络或移除（通过 <code>docker network connect</code> 或 <code>docker network disconnect</code> ，而如果要加入或移除默认网络，需要重建容器。</p></li><li><p>每个自建网络拥有自己的可配置的网桥，可以进行更灵活的网桥参数配置。</p></li><li><p>在默认网络并通过 <code>--link</code> 选项连接的容器可以共享环境变量，但在自建网络中不行。</p></li></ol><h3 id="Docker实现"><a href="#Docker实现" class="headerlink" title="Docker实现"></a>Docker实现</h3><p>Docker的网络模式实际上是基于网络驱动来实现的，要了解网络驱动，需要先了解Docker的网络模型架构。<br>Docker的网络架构基于称为 <strong>容器网络模型 Container Networking Model (CNM)</strong> 的一组接口来实现：</p><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485228_49.png" alt="图片描述"></p><p>图中以Docker Engine为界，上半部分（高层网络设施）是下半部分（驱动）的处理实例。</p><p>CNM与网络驱动的结构和关系：</p><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485279_69.png" alt="图片描述"></p><p>另外还需了解的是：Docker 使用了 Linux 的 <a href="https://coolshell.cn/articles/17010.html">Namespaces</a> 技术来进行资源隔离，如 PID Namespace 隔离进程，Mount Namespace 隔离文件系统，Network Namespace 隔离网络等。一个 Network Namespace 提供了一份独立的网络环境，包括网卡、路由、Iptable 规则等都与其他的 Network Namespace 隔离。</p><ol><li>Host驱动<br>  在Host驱动模式下，docker 不会为容器创建单独的网络 namespace，而是共享主机的 network namespace，也就是说：容器可以直接访问主机上所有的网络信息。</li></ol><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485300_42.png" alt="图片描述"></p><ol><li>Bridge驱动（默认网络）<br>  在Bridge驱动模式下，如果不自行建立网络（ <code>docker network create ...</code> ），会直接使用docker自建的默认网络。docker会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。</li></ol><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485329_29.png" alt="图片描述"></p><p>Docker 完成以上网络配置的过程大致是这样的：<br>在主机上创建一对虚拟网卡 veth pair 设备。veth 设备总是成对出现的，它们组成了一个数据的通道，数据从一个设备进入，就会从另一个设备出来。因此，veth 设备常用来连接两个网络设备。Docker 将 veth pair 设备的一端放在新创建的容器中，并命名为 eth0。另一端放在主机中，以 veth65f9 这样类似的名字命名，并将这个网络设备加入到 docker0 网桥中，可以通过 brctl show 命令查看。</p><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485347_11.png" alt="图片描述"></p><p>从 docker0 子网中分配一个 IP 给容器使用，并设置 docker0 的 IP 地址为容器的默认网关。</p><ol start="3"><li>Bridge驱动（自建网络）</li></ol><p><img src="/tfl/captures/2019-02/tapd_64812569_base64_1550485354_79.png" alt="图片描述"></p><p>与默认网络的区别在于，自行创建了网桥和一个或多个子网。</p><ol start="4"><li>Overlay、MACVLAN、None从略，如需了解请查阅 <a href="https://success.docker.com/article/networking">官方文档</a></li></ol><p>一些细节说明：</p><ol><li>host&#x2F;bridge模式分别基于Host&#x2F;Bridge驱动实现，这很好理解。那么container模式呢？</li></ol><p>实际上container模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，因此可以认为是使用“别人”的驱动来实现。</p><ol start="2"><li>在bridge模式下，docker通过Iptable来实现容器对外是不可见。docker是如何实现的？</li></ol><p>通过宿主机的 iptables 的 <strong>SNAT</strong> 转换。<br>查看包含bridge模式容器的宿主机上的 iptables 规则，可以看到这么一条规则</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE</span><br></pre></td></tr></table></figure><p>这条规则会将源地址为 172.17.0.0&#x2F;16 的包（也就是从 Docker 容器产生的包），并且不是从 docker0 网卡发出的，进行源地址转换，转换成主机网卡的地址。<br>举例说明：假设主机有一块网卡为 eth0，IP 地址为 10.10.101.105&#x2F;24，网关为 10.10.101.254。从主机上一个 IP 为 172.17.0.1&#x2F;16 的容器中 ping 百度（180.76.3.151）。IP 包首先从容器发往自己的默认网关 docker0，包到达 docker0 后，也就到达了主机上。然后会查询主机的路由表，发现包应该从主机的 eth0 发往主机的网关 10.10.105.254&#x2F;24。接着包会转发给 eth0，并从 eth0 发出去（主机的 ip_forward 转发应该已经打开）。这时候，上面的 Iptable 规则就会起作用，对包做 SNAT 转换，将源地址换为 eth0 的地址。这样在外界看来，这个包就是从 10.10.101.105 上发出来的</p><ol start="3"><li>docker如何实现端口映射？</li></ol><p>通过宿主机的 iptables 的 <strong>DNAT</strong> 转换。<br>在进行端口映射之后，查看宿主机的 iptables 规则的变化，发现多了这样一条规则：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-A DOCKER ! -i docker0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 172.17.0.5:80</span><br></pre></td></tr></table></figure><p>此条规则就是对主机 eth0 收到的目的端口为 80 的 tcp 流量进行 DNAT 转换，将流量发往 172.17.0.5:80，也就是我们上面创建的 Docker 容器。所以，外界只需访问 10.10.101.105:80 就可以访问到容器中得服务。</p><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ol><li>容器如何连接和使用宿主机上的服务？</li></ol><p>从上面的内容可以看出，如果可以的话，使用 <code>Host</code> 网络模式，是最方便的，容器里随便怎么连宿主机都毫无成本。<br>其实，即使是 <code>bridge</code> 模式，容器本来也是连接到宿主机的，唯一的一点点障碍，仅仅是宿主机的IP可能是动态的，同时也没有天然的DNS名对应宿主机（其实在Windows、MAC环境有这样的DNS名称，有需要可以查看 host.docker.internal <a href="https://docs.docker.com/docker-for-windows/networking/#i-cannot-ping-my-containers">for windows</a> <a href="https://docs.docker.com/docker-for-mac/networking/#i-cannot-ping-my-containers">for mac</a>）。<br>通过以下方式之一可以在 <code>bridge</code> 模式 找到宿主机的IP：</p><ul><li><p>如果使用默认网络，在宿主机上执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ip addr show docker0 | grep inet</span><br><span class="line">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class="line">    inet6 fe80::42:62ff:fefa:e57c/64 scope link</span><br></pre></td></tr></table></figure><p>其中 <code>172.17.0.1</code> 便是默认网络在宿主机上的IP</p></li><li><p>如果使用自建网络，在宿主机上执行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker network inspect &#123;你的自建网络名称&#125; | grep Gateway</span><br><span class="line">                    &quot;Gateway&quot;: &quot;172.19.0.1&quot;</span><br></pre></td></tr></table></figure><p>其中 <code>172.19.0.1</code> 便是默认网络在宿主机上的IP。<br>其实这种方式也适用于在默认网络情况，将网络名称改为 <code>bridge</code> 即可。</p></li><li><p>在容器中更加简单，执行 <code>ip route show</code> 或</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hostip=$(ip route show | awk &#x27;/default/ &#123;print $3&#125;&#x27;)</span><br><span class="line">$ echo $hostip</span><br></pre></td></tr></table></figure></li><li><p>通过 <code>ifconfig</code> 或 <code>ip addr</code> 获取到宿主机的eth0或外网IP，也是可以的，只是略微有一点性能损失。例如</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hostip=`ip -4 addr show scope global dev eth0 | grep inet | awk &#x27;&#123;print \$2&#125;&#x27; | cut -d / -f 1`</span><br><span class="line">$ echo $hostip</span><br></pre></td></tr></table></figure></li></ul><p>获取到IP之后，还需注意：<br>a. 宿主机需要允许被连接，一般情况应该是可以的，如果不行需要设置 <code>iptables -A INPUT -i docker0 -j ACCEPT</code> 。<br>b. 宿主机上的服务应该监听在 0.0.0.0 或 * （即 <code>INADDR_ANY</code>），可以通过 <code>lsof -i | grep 端口号XXXX</code> 查看。</p><p>另外，为了在容器中更方便的连接宿主机，可以通过传入Host的方式来自行设置一个DNS名称，例如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ HOSTIP=`ip -4 addr show scope global dev eth0 | grep inet | awk &#x27;&#123;print \$2&#125;&#x27; | cut -d / -f 1`</span><br><span class="line">$ docker run  --add-host=docker:$&#123;HOSTIP&#125; --rm -it debian</span><br></pre></td></tr></table></figure><p>在 <code>docker-compose</code> 中则可以通过 <code>extra_hosts</code> 来达到同样的效果，laradock就是通过这样的方式（需要在 .env 中指定 <code>DOCKER_HOST_IP</code> 变量为宿主机IP。</p><ol start="2"><li>一个承载了多个服务API的容器，每个API服务对应不同域名，如果让这些服务更加友好地相互访问？<br>  考虑多个项目共用一个laradock场景，nginx服承载了多个服务API，并对外提供统一的服务端口。而各个服务API的域名和nginx配置设计上是不同的，并存在相互依赖关系。某个服务想使用另一个服务的API时，要求使用默认的主机名域名（nginx）可能造成API路由冲突，各自nginx配置也不方便。如何做到对各个不同域名API的访问都指向同一个nginx容器？<br>  有多种办法解决这个问题，但最简单的，是通过 <code>--net-alias</code> 参数，或者是 docker-compose 的  <code>networks:网络XXX:aliases:</code>，例如在 laradock 的 <code>docker-compose.yml</code> 中有：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nginx:</span><br><span class="line">  ...</span><br><span class="line">  networks:</span><br><span class="line">    frontend:</span><br><span class="line">    backend:</span><br><span class="line">      aliases:</span><br><span class="line">        - account-system.dd01.test</span><br><span class="line">        - account-base-service.dd01.test</span><br><span class="line">        - member-notification-service.dd01.test</span><br><span class="line">        - points-core-system.dd01.test</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>这样就可以通过这里所列出的域名来访问各个服务，由nginx配置来根据域名（ <code>server_name</code>配置 ）分别对应到具体的服务项目。</li></ol><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://docs.docker.com/network/">https://docs.docker.com/network/</a><br><a href="https://success.docker.com/article/networking">https://success.docker.com/article/networking</a> (深入了解推荐)<br><a href="https://docs.docker.com/engine/reference/run/#network-settings">https://docs.docker.com/engine/reference/run/#network-settings</a><br><a href="https://www.infoq.cn/article/docker-network-and-pipework-open-source-explanation-practice">https://www.infoq.cn/article/docker-network-and-pipework-open-source-explanation-practice</a><br><a href="http://cizixs.com/2016/06/01/docker-default-network/">http://cizixs.com/2016/06/01/docker-default-network/</a><br><a href="https://stackoverflow.com/questions/31324981/how-to-access-host-port-from-docker-container">https://stackoverflow.com/questions/31324981/how-to-access-host-port-from-docker-container</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;本次分享没有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker的背景&lt;/li&gt;
&lt;li&gt;Docker的整体架构&lt;/li&gt;
&lt;li&gt;Docker的核心实现技术&lt;/li&gt;
&lt;li&gt;Docker的高级用法&lt;/li&gt;
&lt;li&gt;Docker的使用秘笈&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本次分享是：</summary>
      
    
    
    
    
    <category term="技术" scheme="https://www.wewx.cn/tags/%E6%8A%80%E6%9C%AF/"/>
    
    <category term="Docker" scheme="https://www.wewx.cn/tags/Docker/"/>
    
    <category term="HTTPS" scheme="https://www.wewx.cn/tags/HTTPS/"/>
    
    <category term="网络" scheme="https://www.wewx.cn/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
</feed>
